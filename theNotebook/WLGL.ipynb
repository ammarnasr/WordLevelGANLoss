{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WLGL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n",
        "#clone repo AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "#Downloads birds.zip (6.19M) , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/\n",
        "\n",
        "#Changing Working dirctory to code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "#Download Pillow.rar (251.75K), , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar\n",
        "\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!rm -r /content/CUB-Attn-GAN/\n",
        "\n",
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz\n",
        "\n",
        "os.chdir('/content')\n",
        "!rm -r WordLevelGANLoss\n",
        "!git clone https://github.com/ammarnasr/WordLevelGANLoss.git\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/utils.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/losses.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/trainer.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/config.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/datasets.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/bird_attn2.yml /content/AttnGAN/code/cfg/\n",
        "\n",
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netG_epoch_530.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXS-eOiZPIQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50585c17-56e0-4968-a4a0-bddee28577a6"
      },
      "source": [
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py           --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_470.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:00<00:00, 236MB/s] \n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_470.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS 471\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:438: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  84.02210903167725\n",
            "step :  200 iters_100_time :  78.7211651802063\n",
            "step :  300 iters_100_time :  78.95512437820435\n",
            "step :  400 iters_100_time :  79.46467542648315\n",
            "[471/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 78.44 Time: 354.61s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  46.989686489105225\n",
            "step :  600 iters_100_time :  79.77498745918274\n",
            "step :  700 iters_100_time :  79.91922497749329\n",
            "step :  800 iters_100_time :  78.98178935050964\n",
            "[472/600][442]\n",
            "                    Loss_D: 0.59 Loss_G: 76.93 Time: 352.51s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  13.718659400939941\n",
            "step :  1000 iters_100_time :  78.80468487739563\n",
            "step :  1100 iters_100_time :  79.03336095809937\n",
            "step :  1200 iters_100_time :  79.31114840507507\n",
            "step :  1300 iters_100_time :  78.82174134254456\n",
            "[473/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 59.28 Time: 351.00s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  59.068947076797485\n",
            "step :  1500 iters_100_time :  79.55321526527405\n",
            "step :  1600 iters_100_time :  79.00973272323608\n",
            "step :  1700 iters_100_time :  79.83055305480957\n",
            "[474/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 71.04 Time: 351.44s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  26.63866376876831\n",
            "step :  1900 iters_100_time :  78.19325375556946\n",
            "step :  2000 iters_100_time :  78.7887716293335\n",
            "step :  2100 iters_100_time :  78.96046590805054\n",
            "step :  2200 iters_100_time :  79.17170071601868\n",
            "[475/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 60.77 Time: 350.36s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  71.83092331886292\n",
            "step :  2400 iters_100_time :  79.56086444854736\n",
            "step :  2500 iters_100_time :  79.16701889038086\n",
            "step :  2600 iters_100_time :  79.48773837089539\n",
            "[476/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 57.52 Time: 351.76s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  39.35699129104614\n",
            "step :  2800 iters_100_time :  79.18864107131958\n",
            "step :  2900 iters_100_time :  78.8599853515625\n",
            "step :  3000 iters_100_time :  79.8347008228302\n",
            "[477/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 61.80 Time: 351.83s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  5.8718178272247314\n",
            "step :  3200 iters_100_time :  79.69048547744751\n",
            "step :  3300 iters_100_time :  78.96049213409424\n",
            "step :  3400 iters_100_time :  79.96950697898865\n",
            "step :  3500 iters_100_time :  79.34985685348511\n",
            "[478/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 59.68 Time: 352.74s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  51.68148899078369\n",
            "step :  3700 iters_100_time :  79.85430884361267\n",
            "step :  3800 iters_100_time :  78.94399809837341\n",
            "step :  3900 iters_100_time :  79.59462833404541\n",
            "[479/600][442]\n",
            "                    Loss_D: 4.58 Loss_G: 47.89 Time: 351.87s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  18.45960283279419\n",
            "step :  4100 iters_100_time :  78.86146068572998\n",
            "step :  4200 iters_100_time :  79.93138146400452\n",
            "step :  4300 iters_100_time :  78.36976075172424\n",
            "step :  4400 iters_100_time :  79.50162768363953\n",
            "[480/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 38.22 Time: 351.37s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  63.934643030166626\n",
            "step :  4600 iters_100_time :  79.3008131980896\n",
            "step :  4700 iters_100_time :  79.12799072265625\n",
            "step :  4800 iters_100_time :  79.56418323516846\n",
            "[481/600][442]\n",
            "                    Loss_D: 0.98 Loss_G: 95.32 Time: 351.44s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  30.47273278236389\n",
            "step :  5000 iters_100_time :  79.48779249191284\n",
            "step :  5000 iters_5000_time :  109.96061587333679\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  8.023449420928955\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.49646496772766\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  227.8652422428131\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  5100 iters_100_time :  368.61286187171936\n",
            "step :  5200 iters_100_time :  78.91201972961426\n",
            "step :  5300 iters_100_time :  79.6479115486145\n",
            "[482/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 58.86 Time: 640.71s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  76.85440254211426\n",
            "step :  5500 iters_100_time :  79.55653190612793\n",
            "step :  5600 iters_100_time :  79.1714026927948\n",
            "step :  5700 iters_100_time :  79.71082854270935\n",
            "[483/600][442]\n",
            "                    Loss_D: 0.26 Loss_G: 54.70 Time: 352.30s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  43.908931732177734\n",
            "step :  5900 iters_100_time :  78.83004069328308\n",
            "step :  6000 iters_100_time :  79.94713115692139\n",
            "step :  6100 iters_100_time :  79.51267886161804\n",
            "[484/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 50.59 Time: 352.29s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  10.53666353225708\n",
            "step :  6300 iters_100_time :  79.10583567619324\n",
            "step :  6400 iters_100_time :  79.73068332672119\n",
            "step :  6500 iters_100_time :  79.46799111366272\n",
            "step :  6600 iters_100_time :  78.96167993545532\n",
            "[485/600][442]\n",
            "                    Loss_D: 0.66 Loss_G: 48.40 Time: 352.35s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  56.534077405929565\n",
            "step :  6800 iters_100_time :  80.13083791732788\n",
            "step :  6900 iters_100_time :  79.15773606300354\n",
            "step :  7000 iters_100_time :  80.38821077346802\n",
            "[486/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 89.51 Time: 353.84s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  23.160314083099365\n",
            "step :  7200 iters_100_time :  79.86988115310669\n",
            "step :  7300 iters_100_time :  79.42548751831055\n",
            "step :  7400 iters_100_time :  79.16945147514343\n",
            "step :  7500 iters_100_time :  79.8744764328003\n",
            "[487/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 62.20 Time: 352.76s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  69.4445629119873\n",
            "step :  7700 iters_100_time :  79.8606972694397\n",
            "step :  7800 iters_100_time :  79.48730850219727\n",
            "step :  7900 iters_100_time :  79.86553478240967\n",
            "[488/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 60.79 Time: 354.27s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  35.676605224609375\n",
            "step :  8100 iters_100_time :  79.66384673118591\n",
            "step :  8200 iters_100_time :  79.58577704429626\n",
            "step :  8300 iters_100_time :  79.0705919265747\n",
            "[489/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 64.61 Time: 352.60s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.530088186264038\n",
            "step :  8500 iters_100_time :  80.18449401855469\n",
            "step :  8600 iters_100_time :  79.20566320419312\n",
            "step :  8700 iters_100_time :  79.88326573371887\n",
            "step :  8800 iters_100_time :  79.64341044425964\n",
            "[490/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 59.84 Time: 353.96s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  48.927807569503784\n",
            "step :  9000 iters_100_time :  80.32846689224243\n",
            "step :  9100 iters_100_time :  79.24473857879639\n",
            "step :  9200 iters_100_time :  80.07193970680237\n",
            "[491/600][442]\n",
            "                    Loss_D: 1.04 Loss_G: 76.79 Time: 354.21s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  15.125611305236816\n",
            "step :  9400 iters_100_time :  79.92804622650146\n",
            "step :  9500 iters_100_time :  79.12626528739929\n",
            "step :  9600 iters_100_time :  79.76126790046692\n",
            "step :  9700 iters_100_time :  80.00201487541199\n",
            "[492/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 63.91 Time: 353.11s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  61.60679578781128\n",
            "step :  9900 iters_100_time :  79.93948912620544\n",
            "step :  10000 iters_100_time :  79.35571002960205\n",
            "step :  10000 iters_5000_time :  220.9021453857422\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  8.038049697875977\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  30.260198831558228\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  232.40580821037292\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  10100 iters_100_time :  373.9742338657379\n",
            "[493/600][442]\n",
            "                    Loss_D: 2.33 Loss_G: 47.18 Time: 647.87s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  27.65380024909973\n",
            "step :  10300 iters_100_time :  79.19066095352173\n",
            "step :  10400 iters_100_time :  79.30708408355713\n",
            "step :  10500 iters_100_time :  80.08150458335876\n",
            "step :  10600 iters_100_time :  78.88452219963074\n",
            "[494/600][442]\n",
            "                    Loss_D: 1.78 Loss_G: 79.26 Time: 352.12s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  74.18245244026184\n",
            "step :  10800 iters_100_time :  79.47760319709778\n",
            "step :  10900 iters_100_time :  80.05423212051392\n",
            "step :  11000 iters_100_time :  79.06091380119324\n",
            "[495/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 68.79 Time: 353.33s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  41.075401067733765\n",
            "step :  11200 iters_100_time :  80.25674223899841\n",
            "step :  11300 iters_100_time :  79.15619850158691\n",
            "step :  11400 iters_100_time :  80.05345511436462\n",
            "[496/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 68.92 Time: 354.12s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  7.314545392990112\n",
            "step :  11600 iters_100_time :  79.62025332450867\n",
            "step :  11700 iters_100_time :  79.30353307723999\n",
            "step :  11800 iters_100_time :  79.68321657180786\n",
            "step :  11900 iters_100_time :  79.79526686668396\n",
            "[497/600][442]\n",
            "                    Loss_D: 1.28 Loss_G: 66.92 Time: 353.29s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  53.038302183151245\n",
            "step :  12100 iters_100_time :  79.2604398727417\n",
            "step :  12200 iters_100_time :  79.83492422103882\n",
            "step :  12300 iters_100_time :  79.78803277015686\n",
            "[498/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 49.18 Time: 353.11s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  19.762930870056152\n",
            "step :  12500 iters_100_time :  79.66015911102295\n",
            "step :  12600 iters_100_time :  79.61575865745544\n",
            "step :  12700 iters_100_time :  80.05052661895752\n",
            "step :  12800 iters_100_time :  79.33323955535889\n",
            "[499/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 59.00 Time: 353.45s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  66.52620935440063\n",
            "step :  13000 iters_100_time :  79.35759854316711\n",
            "step :  13100 iters_100_time :  80.11465859413147\n",
            "step :  13200 iters_100_time :  79.43822956085205\n",
            "[500/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 87.84 Time: 354.00s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  33.212363719940186\n",
            "step :  13400 iters_100_time :  79.33874440193176\n",
            "step :  13500 iters_100_time :  80.19223690032959\n",
            "step :  13600 iters_100_time :  79.48266673088074\n",
            "step :  13700 iters_100_time :  79.9782543182373\n",
            "[501/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 48.00 Time: 354.37s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  78.76793026924133\n",
            "step :  13900 iters_100_time :  79.87582659721375\n",
            "step :  14000 iters_100_time :  79.84862518310547\n",
            "step :  14100 iters_100_time :  79.75271534919739\n",
            "[502/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 69.97 Time: 353.64s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  45.7490131855011\n",
            "step :  14300 iters_100_time :  80.04562044143677\n",
            "step :  14400 iters_100_time :  79.90779852867126\n",
            "step :  14500 iters_100_time :  79.54885983467102\n",
            "[503/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 69.98 Time: 354.45s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  11.764375448226929\n",
            "step :  14700 iters_100_time :  80.55045294761658\n",
            "step :  14800 iters_100_time :  79.24408507347107\n",
            "step :  14900 iters_100_time :  80.07901382446289\n",
            "step :  15000 iters_100_time :  79.59812426567078\n",
            "step :  15000 iters_5000_time :  331.2363135814667\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.898183822631836\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.278563976287842\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  231.50999903678894\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[504/600][442]\n",
            "                    Loss_D: 1.32 Loss_G: 44.95 Time: 645.16s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  58.93293380737305\n",
            "step :  15200 iters_100_time :  79.50105881690979\n",
            "step :  15300 iters_100_time :  80.00517272949219\n",
            "step :  15400 iters_100_time :  79.71777653694153\n",
            "[505/600][442]\n",
            "                    Loss_D: 1.30 Loss_G: 46.50 Time: 354.56s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  25.13224959373474\n",
            "step :  15600 iters_100_time :  80.20809936523438\n",
            "step :  15700 iters_100_time :  79.36217665672302\n",
            "step :  15800 iters_100_time :  79.94966769218445\n",
            "step :  15900 iters_100_time :  80.38281321525574\n",
            "[506/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 76.77 Time: 354.90s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  71.37264776229858\n",
            "step :  16100 iters_100_time :  79.92254424095154\n",
            "step :  16200 iters_100_time :  79.61735153198242\n",
            "step :  16300 iters_100_time :  80.12834882736206\n",
            "[507/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 70.75 Time: 354.65s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  37.98556065559387\n",
            "step :  16500 iters_100_time :  79.25236296653748\n",
            "step :  16600 iters_100_time :  80.04492568969727\n",
            "step :  16700 iters_100_time :  80.19623565673828\n",
            "[508/600][442]\n",
            "                    Loss_D: 0.79 Loss_G: 80.40 Time: 353.88s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.7817258834838867\n",
            "step :  16900 iters_100_time :  80.3951301574707\n",
            "step :  17000 iters_100_time :  79.62175369262695\n",
            "step :  17100 iters_100_time :  80.15203666687012\n",
            "step :  17200 iters_100_time :  79.31370782852173\n",
            "[509/600][442]\n",
            "                    Loss_D: 0.93 Loss_G: 84.14 Time: 354.71s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  50.71993923187256\n",
            "step :  17400 iters_100_time :  80.03431725502014\n",
            "step :  17500 iters_100_time :  79.4311945438385\n",
            "step :  17600 iters_100_time :  80.19818663597107\n",
            "[510/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 66.18 Time: 354.43s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  18.05306625366211\n",
            "step :  17800 iters_100_time :  80.08581209182739\n",
            "step :  17900 iters_100_time :  79.42424297332764\n",
            "step :  18000 iters_100_time :  80.06972432136536\n",
            "step :  18100 iters_100_time :  79.76150393486023\n",
            "[511/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 64.33 Time: 355.88s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  63.00280499458313\n",
            "step :  18300 iters_100_time :  79.70879530906677\n",
            "step :  18400 iters_100_time :  79.9157555103302\n",
            "step :  18500 iters_100_time :  80.51969408988953\n",
            "[512/600][442]\n",
            "                    Loss_D: 0.24 Loss_G: 62.26 Time: 354.48s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  29.398889780044556\n",
            "step :  18700 iters_100_time :  79.62564897537231\n",
            "step :  18800 iters_100_time :  80.31157565116882\n",
            "step :  18900 iters_100_time :  80.24687623977661\n",
            "step :  19000 iters_100_time :  80.27787399291992\n",
            "[513/600][442]\n",
            "                    Loss_D: 1.31 Loss_G: 91.55 Time: 355.33s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  76.18453121185303\n",
            "step :  19200 iters_100_time :  80.26289463043213\n",
            "step :  19300 iters_100_time :  79.85539436340332\n",
            "step :  19400 iters_100_time :  79.91737580299377\n",
            "[514/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 75.60 Time: 354.60s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  42.921523094177246\n",
            "step :  19600 iters_100_time :  79.70423722267151\n",
            "step :  19700 iters_100_time :  80.03563523292542\n",
            "step :  19800 iters_100_time :  80.45493626594543\n",
            "[515/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 53.71 Time: 355.51s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  8.682235956192017\n",
            "step :  20000 iters_100_time :  80.44154167175293\n",
            "step :  20000 iters_5000_time :  89.12387728691101\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  8.007534742355347\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.34416913986206\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  237.26223587989807\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  20100 iters_100_time :  378.58828139305115\n",
            "step :  20200 iters_100_time :  80.25266623497009\n",
            "step :  20300 iters_100_time :  80.21912860870361\n",
            "[516/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 62.04 Time: 654.31s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  54.9116268157959\n",
            "step :  20500 iters_100_time :  80.46314644813538\n",
            "step :  20600 iters_100_time :  80.27450942993164\n",
            "step :  20700 iters_100_time :  79.23878765106201\n",
            "[517/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 58.06 Time: 355.41s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  21.710726022720337\n",
            "step :  20900 iters_100_time :  80.15554761886597\n",
            "step :  21000 iters_100_time :  80.46493721008301\n",
            "step :  21100 iters_100_time :  80.85145711898804\n",
            "step :  21200 iters_100_time :  79.70055723190308\n",
            "[518/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 75.92 Time: 356.74s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  68.1253490447998\n",
            "step :  21400 iters_100_time :  79.88420009613037\n",
            "step :  21500 iters_100_time :  79.87593412399292\n",
            "step :  21600 iters_100_time :  79.80950021743774\n",
            "[519/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 61.23 Time: 355.26s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  34.84341764450073\n",
            "step :  21800 iters_100_time :  80.75391817092896\n",
            "step :  21900 iters_100_time :  80.5330457687378\n",
            "step :  22000 iters_100_time :  81.05993461608887\n",
            "step :  22100 iters_100_time :  80.37591981887817\n",
            "[520/600][442]\n",
            "                    Loss_D: 0.49 Loss_G: 71.72 Time: 358.26s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  81.29785871505737\n",
            "step :  22300 iters_100_time :  79.96471095085144\n",
            "step :  22400 iters_100_time :  81.01239061355591\n",
            "step :  22500 iters_100_time :  80.25262427330017\n",
            "[521/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 69.82 Time: 357.11s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  47.70479893684387\n",
            "step :  22700 iters_100_time :  81.0235903263092\n",
            "step :  22800 iters_100_time :  80.67572045326233\n",
            "step :  22900 iters_100_time :  80.63871622085571\n",
            "[522/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 63.36 Time: 358.20s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  13.941635847091675\n",
            "step :  23100 iters_100_time :  80.39588713645935\n",
            "step :  23200 iters_100_time :  80.71067094802856\n",
            "step :  23300 iters_100_time :  80.23362040519714\n",
            "step :  23400 iters_100_time :  80.58013129234314\n",
            "[523/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 65.10 Time: 357.86s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  60.0948851108551\n",
            "step :  23600 iters_100_time :  80.46950340270996\n",
            "step :  23700 iters_100_time :  80.70092797279358\n",
            "step :  23800 iters_100_time :  79.0750458240509\n",
            "[524/600][442]\n",
            "                    Loss_D: 0.54 Loss_G: 47.24 Time: 354.36s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  26.438618898391724\n",
            "step :  24000 iters_100_time :  79.02633547782898\n",
            "step :  24100 iters_100_time :  78.91161918640137\n",
            "step :  24200 iters_100_time :  79.46677255630493\n",
            "step :  24300 iters_100_time :  78.74010181427002\n",
            "[525/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 100.16 Time: 351.29s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  71.87745499610901\n",
            "step :  24500 iters_100_time :  79.28853487968445\n",
            "step :  24600 iters_100_time :  79.217453956604\n",
            "step :  24700 iters_100_time :  78.66801810264587\n",
            "[526/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 55.33 Time: 350.69s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  39.21723961830139\n",
            "step :  24900 iters_100_time :  79.11615586280823\n",
            "step :  25000 iters_100_time :  78.86805033683777\n",
            "step :  25000 iters_5000_time :  197.20157051086426\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.942713975906372\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.22965121269226\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  195.39855790138245\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  327.75545740127563\n",
            "[527/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 66.86 Time: 599.38s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  5.289611339569092\n",
            "step :  25300 iters_100_time :  79.49289441108704\n",
            "step :  25400 iters_100_time :  78.49958753585815\n",
            "step :  25500 iters_100_time :  79.1463451385498\n",
            "step :  25600 iters_100_time :  78.89634108543396\n",
            "[528/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 78.53 Time: 350.27s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  51.11594247817993\n",
            "step :  25800 iters_100_time :  79.06834888458252\n",
            "step :  25900 iters_100_time :  78.9576427936554\n",
            "step :  26000 iters_100_time :  78.52598142623901\n",
            "[529/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 59.99 Time: 349.65s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  18.0228271484375\n",
            "step :  26200 iters_100_time :  79.4087221622467\n",
            "step :  26300 iters_100_time :  79.22421765327454\n",
            "step :  26400 iters_100_time :  79.31349968910217\n",
            "step :  26500 iters_100_time :  78.80682301521301\n",
            "[530/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 61.18 Time: 350.83s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  26600 iters_100_time :  64.00091910362244\n",
            "step :  26700 iters_100_time :  78.55585026741028\n",
            "step :  26800 iters_100_time :  79.33433818817139\n",
            "step :  26900 iters_100_time :  78.88844847679138\n",
            "[531/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 59.18 Time: 350.92s\n",
            "num_batches :  442\n",
            "step :  27000 iters_100_time :  30.599334239959717\n",
            "step :  27100 iters_100_time :  78.72117757797241\n",
            "step :  27200 iters_100_time :  79.47712635993958\n",
            "step :  27300 iters_100_time :  79.64746594429016\n",
            "step :  27400 iters_100_time :  78.70701718330383\n",
            "[532/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 64.99 Time: 350.23s\n",
            "num_batches :  442\n",
            "step :  27500 iters_100_time :  76.81537342071533\n",
            "step :  27600 iters_100_time :  78.81226658821106\n",
            "step :  27700 iters_100_time :  79.17070436477661\n",
            "step :  27800 iters_100_time :  79.40601396560669\n",
            "[533/600][442]\n",
            "                    Loss_D: 0.26 Loss_G: 70.79 Time: 351.11s\n",
            "num_batches :  442\n",
            "step :  27900 iters_100_time :  42.88246512413025\n",
            "step :  28000 iters_100_time :  79.13413906097412\n",
            "step :  28100 iters_100_time :  79.23384499549866\n",
            "step :  28200 iters_100_time :  79.61024069786072\n",
            "[534/600][442]\n",
            "                    Loss_D: 1.81 Loss_G: 76.10 Time: 350.61s\n",
            "num_batches :  442\n",
            "step :  28300 iters_100_time :  10.095209836959839\n",
            "step :  28400 iters_100_time :  78.85531759262085\n",
            "step :  28500 iters_100_time :  79.22729516029358\n",
            "step :  28600 iters_100_time :  78.76475405693054\n",
            "step :  28700 iters_100_time :  79.54397583007812\n",
            "[535/600][442]\n",
            "                    Loss_D: 0.27 Loss_G: 59.42 Time: 350.26s\n",
            "num_batches :  442\n",
            "step :  28800 iters_100_time :  55.18738603591919\n",
            "step :  28900 iters_100_time :  78.63182139396667\n",
            "step :  29000 iters_100_time :  79.79099488258362\n",
            "step :  29100 iters_100_time :  78.5911157131195\n",
            "[536/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 67.73 Time: 349.54s\n",
            "num_batches :  442\n",
            "step :  29200 iters_100_time :  23.59902310371399\n",
            "step :  29300 iters_100_time :  79.81796765327454\n",
            "step :  29400 iters_100_time :  78.8361337184906\n",
            "step :  29500 iters_100_time :  79.63016963005066\n",
            "step :  29600 iters_100_time :  79.107426404953\n",
            "[537/600][442]\n",
            "                    Loss_D: 2.18 Loss_G: 64.85 Time: 352.34s\n",
            "num_batches :  442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFHcQmD6nzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}