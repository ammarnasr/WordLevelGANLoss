{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WLGL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "94218996-07cd-4a97-b0f7-3cf05b528614"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 10 08:56:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n",
        "#clone repo AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "#Downloads birds.zip (6.19M) , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/\n",
        "\n",
        "#Changing Working dirctory to code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "#Download Pillow.rar (251.75K), , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar\n",
        "\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!rm -r /content/CUB-Attn-GAN/\n",
        "\n",
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz\n",
        "\n",
        "os.chdir('/content')\n",
        "!rm -r WordLevelGANLoss\n",
        "!git clone https://github.com/ammarnasr/WordLevelGANLoss.git\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/utils.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/losses.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/trainer.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/config.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/datasets.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/bird_attn2.yml /content/AttnGAN/code/cfg/\n",
        "\n",
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netG_epoch_90.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXS-eOiZPIQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30390f92-d28c-4d24-9e18-8a5d9fe42ecc"
      },
      "source": [
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py           --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_90.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 99.3MB/s] \n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_90.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS 91\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:438: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  74.6762170791626\n",
            "step :  200 iters_100_time :  69.97822189331055\n",
            "step :  300 iters_100_time :  70.06608200073242\n",
            "step :  400 iters_100_time :  70.34218072891235\n",
            "[91/600][442]\n",
            "                    Loss_D: 1.24 Loss_G: 43.28 Time: 314.47s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  41.2692174911499\n",
            "step :  600 iters_100_time :  70.00574064254761\n",
            "step :  700 iters_100_time :  70.23210763931274\n",
            "step :  800 iters_100_time :  69.81570553779602\n",
            "[92/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 48.53 Time: 310.43s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  11.920515775680542\n",
            "step :  1000 iters_100_time :  70.23960161209106\n",
            "step :  1100 iters_100_time :  69.95200490951538\n",
            "step :  1200 iters_100_time :  69.99468851089478\n",
            "step :  1300 iters_100_time :  70.2164957523346\n",
            "[93/600][442]\n",
            "                    Loss_D: 0.53 Loss_G: 39.28 Time: 310.91s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  52.600951194763184\n",
            "step :  1500 iters_100_time :  70.21699404716492\n",
            "step :  1600 iters_100_time :  70.27061700820923\n",
            "step :  1700 iters_100_time :  69.97325396537781\n",
            "[94/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 53.10 Time: 311.02s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  23.073665857315063\n",
            "step :  1900 iters_100_time :  70.27976870536804\n",
            "step :  2000 iters_100_time :  69.97706317901611\n",
            "step :  2100 iters_100_time :  70.15674710273743\n",
            "step :  2200 iters_100_time :  70.12304759025574\n",
            "[95/600][442]\n",
            "                    Loss_D: 4.53 Loss_G: 31.30 Time: 310.82s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  63.54828119277954\n",
            "step :  2400 iters_100_time :  69.93049430847168\n",
            "step :  2500 iters_100_time :  70.06523942947388\n",
            "step :  2600 iters_100_time :  69.76655197143555\n",
            "[96/600][442]\n",
            "                    Loss_D: 0.46 Loss_G: 31.85 Time: 310.20s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  34.22369432449341\n",
            "step :  2800 iters_100_time :  70.03172779083252\n",
            "step :  2900 iters_100_time :  69.61907911300659\n",
            "step :  3000 iters_100_time :  69.97163677215576\n",
            "[97/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 47.86 Time: 309.99s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  4.906443119049072\n",
            "step :  3200 iters_100_time :  69.67848873138428\n",
            "step :  3300 iters_100_time :  69.877445936203\n",
            "step :  3400 iters_100_time :  70.02258086204529\n",
            "step :  3500 iters_100_time :  69.73493814468384\n",
            "[98/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 51.23 Time: 309.90s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  45.33650517463684\n",
            "step :  3700 iters_100_time :  70.02397584915161\n",
            "step :  3800 iters_100_time :  69.70470094680786\n",
            "step :  3900 iters_100_time :  69.85811495780945\n",
            "[99/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 49.89 Time: 309.81s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  16.184720754623413\n",
            "step :  4100 iters_100_time :  69.66203737258911\n",
            "step :  4200 iters_100_time :  69.91312575340271\n",
            "step :  4300 iters_100_time :  70.03828692436218\n",
            "step :  4400 iters_100_time :  69.85122394561768\n",
            "[100/600][442]\n",
            "                    Loss_D: 0.49 Loss_G: 51.68 Time: 309.89s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  56.79452323913574\n",
            "step :  4600 iters_100_time :  70.03462719917297\n",
            "step :  4700 iters_100_time :  69.87768316268921\n",
            "step :  4800 iters_100_time :  70.01064586639404\n",
            "[101/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 46.92 Time: 310.47s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  27.28643250465393\n",
            "step :  5000 iters_100_time :  69.81633520126343\n",
            "step :  5000 iters_5000_time :  97.10283899307251\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.132838010787964\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  27.113032817840576\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  214.4168701171875\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  5100 iters_100_time :  340.21854972839355\n",
            "step :  5200 iters_100_time :  70.03411483764648\n",
            "step :  5300 iters_100_time :  70.12157464027405\n",
            "[102/600][442]\n",
            "                    Loss_D: 0.54 Loss_G: 65.69 Time: 580.47s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  67.64900851249695\n",
            "step :  5500 iters_100_time :  70.03302025794983\n",
            "step :  5600 iters_100_time :  70.11110663414001\n",
            "step :  5700 iters_100_time :  69.91133165359497\n",
            "[103/600][442]\n",
            "                    Loss_D: 0.63 Loss_G: 34.93 Time: 310.25s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  38.40916991233826\n",
            "step :  5900 iters_100_time :  69.92956209182739\n",
            "step :  6000 iters_100_time :  70.1962194442749\n",
            "step :  6100 iters_100_time :  69.86522340774536\n",
            "[104/600][442]\n",
            "                    Loss_D: 0.27 Loss_G: 47.31 Time: 310.45s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  9.046211957931519\n",
            "step :  6300 iters_100_time :  70.12966871261597\n",
            "step :  6400 iters_100_time :  69.88532543182373\n",
            "step :  6500 iters_100_time :  70.07302117347717\n",
            "step :  6600 iters_100_time :  70.29796147346497\n",
            "[105/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 51.82 Time: 310.67s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  49.68062233924866\n",
            "step :  6800 iters_100_time :  69.94264388084412\n",
            "step :  6900 iters_100_time :  70.28153872489929\n",
            "step :  7000 iters_100_time :  69.90848207473755\n",
            "[106/600][442]\n",
            "                    Loss_D: 0.93 Loss_G: 49.99 Time: 310.69s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  20.25775384902954\n",
            "step :  7200 iters_100_time :  70.1292495727539\n",
            "step :  7300 iters_100_time :  69.91752028465271\n",
            "step :  7400 iters_100_time :  69.97879076004028\n",
            "step :  7500 iters_100_time :  70.13366293907166\n",
            "[107/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 49.45 Time: 310.44s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  60.841694355010986\n",
            "step :  7700 iters_100_time :  69.93810200691223\n",
            "step :  7800 iters_100_time :  70.19879078865051\n",
            "step :  7900 iters_100_time :  69.7725977897644\n",
            "[108/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 47.94 Time: 310.38s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  31.41583013534546\n",
            "step :  8100 iters_100_time :  69.98293375968933\n",
            "step :  8200 iters_100_time :  69.96170496940613\n",
            "step :  8300 iters_100_time :  69.98960566520691\n",
            "[109/600][442]\n",
            "                    Loss_D: 3.72 Loss_G: 31.09 Time: 310.30s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.1682381629943848\n",
            "step :  8500 iters_100_time :  69.7489185333252\n",
            "step :  8600 iters_100_time :  69.9566445350647\n",
            "step :  8700 iters_100_time :  70.21374320983887\n",
            "step :  8800 iters_100_time :  69.9022741317749\n",
            "[110/600][442]\n",
            "                    Loss_D: 0.53 Loss_G: 35.84 Time: 310.33s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  42.682514905929565\n",
            "step :  9000 iters_100_time :  70.07577633857727\n",
            "step :  9100 iters_100_time :  70.14728331565857\n",
            "step :  9200 iters_100_time :  69.88732624053955\n",
            "[111/600][442]\n",
            "                    Loss_D: 1.50 Loss_G: 43.49 Time: 310.91s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  13.276161432266235\n",
            "step :  9400 iters_100_time :  70.10729479789734\n",
            "step :  9500 iters_100_time :  69.92672538757324\n",
            "step :  9600 iters_100_time :  70.0907142162323\n",
            "step :  9700 iters_100_time :  70.20719289779663\n",
            "[112/600][442]\n",
            "                    Loss_D: 1.02 Loss_G: 49.43 Time: 310.68s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  53.776758432388306\n",
            "step :  9900 iters_100_time :  70.02658009529114\n",
            "step :  10000 iters_100_time :  70.2596492767334\n",
            "step :  10000 iters_5000_time :  194.0631034374237\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.959939002990723\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.66328454017639\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  212.7689266204834\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  10100 iters_100_time :  337.0180330276489\n",
            "[113/600][442]\n",
            "                    Loss_D: 1.94 Loss_G: 53.72 Time: 577.63s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  24.424839735031128\n",
            "step :  10300 iters_100_time :  70.03414630889893\n",
            "step :  10400 iters_100_time :  70.17897534370422\n",
            "step :  10500 iters_100_time :  70.01608872413635\n",
            "step :  10600 iters_100_time :  69.96307158470154\n",
            "[114/600][442]\n",
            "                    Loss_D: 2.43 Loss_G: 63.20 Time: 310.82s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  65.18329620361328\n",
            "step :  10800 iters_100_time :  69.85342240333557\n",
            "step :  10900 iters_100_time :  70.29197382926941\n",
            "step :  11000 iters_100_time :  70.27226495742798\n",
            "[115/600][442]\n",
            "                    Loss_D: 0.58 Loss_G: 52.47 Time: 310.96s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  35.57912826538086\n",
            "step :  11200 iters_100_time :  70.20065641403198\n",
            "step :  11300 iters_100_time :  70.2881863117218\n",
            "step :  11400 iters_100_time :  70.03457951545715\n",
            "[116/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 56.24 Time: 311.10s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.116121530532837\n",
            "step :  11600 iters_100_time :  70.32748913764954\n",
            "step :  11700 iters_100_time :  69.96682238578796\n",
            "step :  11800 iters_100_time :  70.15683627128601\n",
            "step :  11900 iters_100_time :  70.30763411521912\n",
            "[117/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 39.33 Time: 310.99s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  46.89465045928955\n",
            "step :  12100 iters_100_time :  70.03541135787964\n",
            "step :  12200 iters_100_time :  70.26942920684814\n",
            "step :  12300 iters_100_time :  69.96706080436707\n",
            "[118/600][442]\n",
            "                    Loss_D: 2.64 Loss_G: 33.27 Time: 311.00s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  17.552995204925537\n",
            "step :  12500 iters_100_time :  70.25867223739624\n",
            "step :  12600 iters_100_time :  70.0282289981842\n",
            "step :  12700 iters_100_time :  69.99606156349182\n",
            "step :  12800 iters_100_time :  70.40529036521912\n",
            "[119/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 49.50 Time: 311.19s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  58.05193543434143\n",
            "step :  13000 iters_100_time :  70.14471483230591\n",
            "step :  13100 iters_100_time :  70.17919325828552\n",
            "step :  13200 iters_100_time :  70.0255434513092\n",
            "[120/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 55.52 Time: 310.99s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  28.623873949050903\n",
            "step :  13400 iters_100_time :  70.0796000957489\n",
            "step :  13500 iters_100_time :  70.27339720726013\n",
            "step :  13600 iters_100_time :  70.1175684928894\n",
            "step :  13700 iters_100_time :  69.99840354919434\n",
            "[121/600][442]\n",
            "                    Loss_D: 0.24 Loss_G: 51.46 Time: 311.15s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  69.36570167541504\n",
            "step :  13900 iters_100_time :  70.08440017700195\n",
            "step :  14000 iters_100_time :  70.05857944488525\n",
            "step :  14100 iters_100_time :  70.36006140708923\n",
            "[122/600][442]\n",
            "                    Loss_D: 0.69 Loss_G: 53.76 Time: 311.17s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  39.84540915489197\n",
            "step :  14300 iters_100_time :  70.13742136955261\n",
            "step :  14400 iters_100_time :  70.1666808128357\n",
            "step :  14500 iters_100_time :  69.98489499092102\n",
            "[123/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 43.33 Time: 310.93s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  10.409400224685669\n",
            "step :  14700 iters_100_time :  70.01888036727905\n",
            "step :  14800 iters_100_time :  70.04562187194824\n",
            "step :  14900 iters_100_time :  70.13394546508789\n",
            "step :  15000 iters_100_time :  70.28263592720032\n",
            "step :  15000 iters_5000_time :  290.8906669616699\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.99285626411438\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.553910732269287\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  213.66904258728027\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[124/600][442]\n",
            "                    Loss_D: 0.97 Loss_G: 42.27 Time: 578.18s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  51.23038911819458\n",
            "step :  15200 iters_100_time :  69.99308800697327\n",
            "step :  15300 iters_100_time :  70.14294099807739\n",
            "step :  15400 iters_100_time :  70.3035671710968\n",
            "[125/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 48.44 Time: 311.33s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  21.66716170310974\n",
            "step :  15600 iters_100_time :  70.14117646217346\n",
            "step :  15700 iters_100_time :  70.33708500862122\n",
            "step :  15800 iters_100_time :  70.21842193603516\n",
            "step :  15900 iters_100_time :  70.39710402488708\n",
            "[126/600][442]\n",
            "                    Loss_D: 0.39 Loss_G: 51.70 Time: 311.66s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  62.69007587432861\n",
            "step :  16100 iters_100_time :  70.21449017524719\n",
            "step :  16200 iters_100_time :  70.44542360305786\n",
            "step :  16300 iters_100_time :  70.55656886100769\n",
            "[127/600][442]\n",
            "                    Loss_D: 0.71 Loss_G: 54.75 Time: 312.11s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  32.86635756492615\n",
            "step :  16500 iters_100_time :  70.32340359687805\n",
            "step :  16600 iters_100_time :  70.25449705123901\n",
            "step :  16700 iters_100_time :  70.13692164421082\n",
            "[128/600][442]\n",
            "                    Loss_D: 1.41 Loss_G: 56.77 Time: 311.64s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.4172627925872803\n",
            "step :  16900 iters_100_time :  70.31822419166565\n",
            "step :  17000 iters_100_time :  70.06362795829773\n",
            "step :  17100 iters_100_time :  70.10426759719849\n",
            "step :  17200 iters_100_time :  70.42692446708679\n",
            "[129/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 60.91 Time: 311.59s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  44.40090727806091\n",
            "step :  17400 iters_100_time :  70.38539338111877\n",
            "step :  17500 iters_100_time :  70.59431886672974\n",
            "step :  17600 iters_100_time :  70.1919481754303\n",
            "[130/600][442]\n",
            "                    Loss_D: 0.86 Loss_G: 53.84 Time: 312.25s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  14.818219661712646\n",
            "step :  17800 iters_100_time :  70.33490657806396\n",
            "step :  17900 iters_100_time :  70.4093554019928\n",
            "step :  18000 iters_100_time :  70.31014609336853\n",
            "step :  18100 iters_100_time :  70.38239741325378\n",
            "[131/600][442]\n",
            "                    Loss_D: 0.53 Loss_G: 50.51 Time: 312.48s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  55.65902042388916\n",
            "step :  18300 iters_100_time :  70.15395665168762\n",
            "step :  18400 iters_100_time :  70.47327136993408\n",
            "step :  18500 iters_100_time :  70.54305672645569\n",
            "[132/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 56.61 Time: 312.35s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  25.8911771774292\n",
            "step :  18700 iters_100_time :  70.30355072021484\n",
            "step :  18800 iters_100_time :  70.52914309501648\n",
            "step :  18900 iters_100_time :  70.31449007987976\n",
            "step :  19000 iters_100_time :  70.36064076423645\n",
            "[133/600][442]\n",
            "                    Loss_D: 1.36 Loss_G: 28.95 Time: 312.09s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  67.17666625976562\n",
            "step :  19200 iters_100_time :  70.36324119567871\n",
            "step :  19300 iters_100_time :  70.3072681427002\n",
            "step :  19400 iters_100_time :  70.72225141525269\n",
            "[134/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 59.60 Time: 312.98s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  37.22875452041626\n",
            "step :  19600 iters_100_time :  70.46362471580505\n",
            "step :  19700 iters_100_time :  70.48171782493591\n",
            "step :  19800 iters_100_time :  70.40302014350891\n",
            "[135/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 76.84 Time: 312.58s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  7.616227626800537\n",
            "step :  20000 iters_100_time :  70.41372108459473\n",
            "step :  20000 iters_5000_time :  78.03001999855042\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.043981313705444\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  27.188705682754517\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  214.65520548820496\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  20100 iters_100_time :  340.5228328704834\n",
            "step :  20200 iters_100_time :  70.11164116859436\n",
            "step :  20300 iters_100_time :  70.3138861656189\n",
            "[136/600][442]\n",
            "                    Loss_D: 2.07 Loss_G: 43.31 Time: 581.97s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  48.22986149787903\n",
            "step :  20500 iters_100_time :  70.26184821128845\n",
            "step :  20600 iters_100_time :  70.48551797866821\n",
            "step :  20700 iters_100_time :  70.56248450279236\n",
            "[137/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 50.19 Time: 312.07s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  19.084171772003174\n",
            "step :  20900 iters_100_time :  70.77330923080444\n",
            "step :  21000 iters_100_time :  70.77248978614807\n",
            "step :  21100 iters_100_time :  70.52092123031616\n",
            "step :  21200 iters_100_time :  70.54241752624512\n",
            "[138/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 54.64 Time: 313.67s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  59.958800077438354\n",
            "step :  21400 iters_100_time :  70.36315822601318\n",
            "step :  21500 iters_100_time :  70.55229306221008\n",
            "step :  21600 iters_100_time :  70.79315495491028\n",
            "[139/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 49.54 Time: 313.03s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  30.190444469451904\n",
            "step :  21800 iters_100_time :  70.47297787666321\n",
            "step :  21900 iters_100_time :  70.72142457962036\n",
            "step :  22000 iters_100_time :  70.53078985214233\n",
            "step :  22100 iters_100_time :  70.5409984588623\n",
            "[140/600][442]\n",
            "                    Loss_D: 0.55 Loss_G: 52.78 Time: 312.96s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  71.18879866600037\n",
            "step :  22300 iters_100_time :  70.71283173561096\n",
            "step :  22400 iters_100_time :  70.48948192596436\n",
            "step :  22500 iters_100_time :  70.63571095466614\n",
            "[141/600][442]\n",
            "                    Loss_D: 0.96 Loss_G: 37.42 Time: 313.41s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  41.8816819190979\n",
            "step :  22700 iters_100_time :  70.63870429992676\n",
            "step :  22800 iters_100_time :  70.53960752487183\n",
            "step :  22900 iters_100_time :  70.76355504989624\n",
            "[142/600][442]\n",
            "                    Loss_D: 0.88 Loss_G: 40.13 Time: 313.65s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  11.876305341720581\n",
            "step :  23100 iters_100_time :  70.7237491607666\n",
            "step :  23200 iters_100_time :  70.86462783813477\n",
            "step :  23300 iters_100_time :  70.56717705726624\n",
            "step :  23400 iters_100_time :  70.68967485427856\n",
            "[143/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 51.80 Time: 313.51s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  52.76754665374756\n",
            "step :  23600 iters_100_time :  70.28032875061035\n",
            "step :  23700 iters_100_time :  70.50459003448486\n",
            "step :  23800 iters_100_time :  70.65955066680908\n",
            "[144/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 64.38 Time: 312.57s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  23.19090962409973\n",
            "step :  24000 iters_100_time :  70.58658957481384\n",
            "step :  24100 iters_100_time :  70.67986941337585\n",
            "step :  24200 iters_100_time :  70.5159387588501\n",
            "step :  24300 iters_100_time :  70.5448362827301\n",
            "[145/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 55.20 Time: 313.28s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  64.41288685798645\n",
            "step :  24500 iters_100_time :  70.43413352966309\n",
            "step :  24600 iters_100_time :  70.54633021354675\n",
            "step :  24700 iters_100_time :  70.7419261932373\n",
            "[146/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 46.56 Time: 313.02s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  34.39014458656311\n",
            "step :  24900 iters_100_time :  70.58867979049683\n",
            "step :  25000 iters_100_time :  70.59616303443909\n",
            "step :  25000 iters_5000_time :  175.57509779930115\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.0268425941467285\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.801714181900024\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  204.89729475975037\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  330.36386227607727\n",
            "[147/600][442]\n",
            "                    Loss_D: 1.92 Loss_G: 42.81 Time: 572.50s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  4.713668584823608\n",
            "step :  25300 iters_100_time :  70.56725406646729\n",
            "step :  25400 iters_100_time :  70.63632941246033\n",
            "step :  25500 iters_100_time :  70.41492795944214\n",
            "step :  25600 iters_100_time :  70.74830341339111\n",
            "[148/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 56.78 Time: 313.18s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  45.897164821624756\n",
            "step :  25800 iters_100_time :  70.70480418205261\n",
            "step :  25900 iters_100_time :  70.64106488227844\n",
            "step :  26000 iters_100_time :  70.8919289112091\n",
            "[149/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 43.77 Time: 313.79s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  16.1475350856781\n",
            "step :  26200 iters_100_time :  70.78061532974243\n",
            "step :  26300 iters_100_time :  70.9337522983551\n",
            "step :  26400 iters_100_time :  70.62450385093689\n",
            "step :  26500 iters_100_time :  70.68622088432312\n",
            "[150/600][442]\n",
            "                    Loss_D: 1.17 Loss_G: 60.09 Time: 313.77s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  26600 iters_100_time :  57.13388442993164\n",
            "step :  26700 iters_100_time :  70.77441811561584\n",
            "step :  26800 iters_100_time :  70.74376034736633\n",
            "step :  26900 iters_100_time :  70.68997550010681\n",
            "[151/600][442]\n",
            "                    Loss_D: 0.21 Loss_G: 45.31 Time: 313.96s\n",
            "num_batches :  442\n",
            "step :  27000 iters_100_time :  27.513137578964233\n",
            "step :  27100 iters_100_time :  70.48365449905396\n",
            "step :  27200 iters_100_time :  70.75750231742859\n",
            "step :  27300 iters_100_time :  71.10640597343445\n",
            "step :  27400 iters_100_time :  70.99681878089905\n",
            "[152/600][442]\n",
            "                    Loss_D: 1.29 Loss_G: 34.31 Time: 314.33s\n",
            "num_batches :  442\n",
            "step :  27500 iters_100_time :  68.48754382133484\n",
            "step :  27600 iters_100_time :  70.94829511642456\n",
            "step :  27700 iters_100_time :  70.63391160964966\n",
            "step :  27800 iters_100_time :  70.72805452346802\n",
            "[153/600][442]\n",
            "                    Loss_D: 0.21 Loss_G: 54.35 Time: 313.90s\n",
            "num_batches :  442\n",
            "step :  27900 iters_100_time :  38.996105670928955\n",
            "step :  28000 iters_100_time :  70.69904851913452\n",
            "step :  28100 iters_100_time :  71.00066423416138\n",
            "step :  28200 iters_100_time :  71.1021420955658\n",
            "[154/600][442]\n",
            "                    Loss_D: 0.88 Loss_G: 62.10 Time: 314.37s\n",
            "num_batches :  442\n",
            "step :  28300 iters_100_time :  9.093344926834106\n",
            "step :  28400 iters_100_time :  70.73534655570984\n",
            "step :  28500 iters_100_time :  70.95821785926819\n",
            "step :  28600 iters_100_time :  70.72771859169006\n",
            "step :  28700 iters_100_time :  70.95521879196167\n",
            "[155/600][442]\n",
            "                    Loss_D: 0.33 Loss_G: 50.54 Time: 314.45s\n",
            "num_batches :  442\n",
            "step :  28800 iters_100_time :  50.2908399105072\n",
            "step :  28900 iters_100_time :  70.72934985160828\n",
            "step :  29000 iters_100_time :  71.01601338386536\n",
            "step :  29100 iters_100_time :  71.11700677871704\n",
            "[156/600][442]\n",
            "                    Loss_D: 0.40 Loss_G: 54.95 Time: 314.79s\n",
            "num_batches :  442\n",
            "step :  29200 iters_100_time :  20.426023244857788\n",
            "step :  29300 iters_100_time :  71.24172377586365\n",
            "step :  29400 iters_100_time :  71.09804058074951\n",
            "step :  29500 iters_100_time :  70.85806250572205\n",
            "step :  29600 iters_100_time :  71.13314199447632\n",
            "[157/600][442]\n",
            "                    Loss_D: 0.96 Loss_G: 61.01 Time: 315.23s\n",
            "num_batches :  442\n",
            "step :  29700 iters_100_time :  61.71093535423279\n",
            "step :  29800 iters_100_time :  70.72998666763306\n",
            "step :  29900 iters_100_time :  71.04548716545105\n",
            "step :  30000 iters_100_time :  71.4586443901062\n",
            "step :  30000 iters_5000_time :  274.94520711898804\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.9624927043914795\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.80836510658264\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  213.20243430137634\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[158/600][442]\n",
            "                    Loss_D: 1.90 Loss_G: 65.23 Time: 583.25s\n",
            "num_batches :  442\n",
            "step :  30100 iters_100_time :  31.786193132400513\n",
            "step :  30200 iters_100_time :  71.03212833404541\n",
            "step :  30300 iters_100_time :  71.22182440757751\n",
            "step :  30400 iters_100_time :  71.26991724967957\n",
            "[159/600][442]\n",
            "                    Loss_D: 3.40 Loss_G: 62.99 Time: 315.86s\n",
            "num_batches :  442\n",
            "step :  30500 iters_100_time :  2.0675113201141357\n",
            "step :  30600 iters_100_time :  71.07483172416687\n",
            "step :  30700 iters_100_time :  71.31833982467651\n",
            "step :  30800 iters_100_time :  71.04479384422302\n",
            "step :  30900 iters_100_time :  71.1278326511383\n",
            "[160/600][442]\n",
            "                    Loss_D: 0.78 Loss_G: 50.70 Time: 315.71s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  31000 iters_100_time :  43.505457162857056\n",
            "step :  31100 iters_100_time :  71.31956076622009\n",
            "step :  31200 iters_100_time :  71.50126695632935\n",
            "step :  31300 iters_100_time :  71.18345761299133\n",
            "[161/600][442]\n",
            "                    Loss_D: 0.91 Loss_G: 71.87 Time: 316.69s\n",
            "num_batches :  442\n",
            "step :  31400 iters_100_time :  13.22977089881897\n",
            "step :  31500 iters_100_time :  71.52222442626953\n",
            "step :  31600 iters_100_time :  70.99745559692383\n",
            "step :  31700 iters_100_time :  71.33650088310242\n",
            "step :  31800 iters_100_time :  71.61194849014282\n",
            "[162/600][442]\n",
            "                    Loss_D: 2.09 Loss_G: 74.31 Time: 316.21s\n",
            "num_batches :  442\n",
            "step :  31900 iters_100_time :  54.8695387840271\n",
            "step :  32000 iters_100_time :  71.37863373756409\n",
            "step :  32100 iters_100_time :  71.32372879981995\n",
            "step :  32200 iters_100_time :  71.24334406852722\n",
            "[163/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 53.21 Time: 316.44s\n",
            "num_batches :  442\n",
            "step :  32300 iters_100_time :  24.899867057800293\n",
            "step :  32400 iters_100_time :  71.85255694389343\n",
            "step :  32500 iters_100_time :  71.10557198524475\n",
            "step :  32600 iters_100_time :  71.32686495780945\n",
            "step :  32700 iters_100_time :  71.74778485298157\n",
            "[164/600][442]\n",
            "                    Loss_D: 0.45 Loss_G: 59.01 Time: 316.91s\n",
            "num_batches :  442\n",
            "step :  32800 iters_100_time :  66.43626546859741\n",
            "step :  32900 iters_100_time :  71.43956446647644\n",
            "step :  33000 iters_100_time :  71.7349739074707\n",
            "step :  33100 iters_100_time :  71.2744505405426\n",
            "[165/600][442]\n",
            "                    Loss_D: 0.31 Loss_G: 52.63 Time: 317.36s\n",
            "num_batches :  442\n",
            "step :  33200 iters_100_time :  36.199002265930176\n",
            "step :  33300 iters_100_time :  71.62699103355408\n",
            "step :  33400 iters_100_time :  71.16924262046814\n",
            "step :  33500 iters_100_time :  71.49835848808289\n",
            "[166/600][442]\n",
            "                    Loss_D: 1.10 Loss_G: 37.15 Time: 316.92s\n",
            "num_batches :  442\n",
            "step :  33600 iters_100_time :  6.462358713150024\n",
            "step :  33700 iters_100_time :  71.09224581718445\n",
            "step :  33800 iters_100_time :  71.39297032356262\n",
            "step :  33900 iters_100_time :  71.62460994720459\n",
            "step :  34000 iters_100_time :  71.32012391090393\n",
            "[167/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 65.15 Time: 316.61s\n",
            "num_batches :  442\n",
            "step :  34100 iters_100_time :  47.92822861671448\n",
            "step :  34200 iters_100_time :  71.6050066947937\n",
            "step :  34300 iters_100_time :  71.30248594284058\n",
            "step :  34400 iters_100_time :  71.65443277359009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0i8h7SFRIoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}