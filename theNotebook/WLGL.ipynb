{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WLGL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "15bbb929-568b-45cd-8c9d-a00e3ce0cd61"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 17 19:11:03 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d14d1daa-c9ac-49bc-a9fa-1d3e824f2b83"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n",
        "#clone repo AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "#Downloads birds.zip (6.19M) , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/\n",
        "\n",
        "#Changing Working dirctory to code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "#Download Pillow.rar (251.75K), , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar\n",
        "\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!rm -r /content/CUB-Attn-GAN/\n",
        "\n",
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz\n",
        "\n",
        "os.chdir('/content')\n",
        "!rm -r WordLevelGANLoss\n",
        "!git clone https://github.com/ammarnasr/WordLevelGANLoss.git\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/utils.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/losses.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/trainer.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/config.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/datasets.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/bird_attn2.yml /content/AttnGAN/code/cfg/\n",
        "\n",
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netG_epoch_590.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 9.77 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "--2020-08-17 19:12:42--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.125.102, 108.177.125.138, 108.177.125.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.125.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7qijra9dvebkbataho804btaj4uhte12/1597691550000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-17 19:13:12--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/7qijra9dvebkbataho804btaj4uhte12/1597691550000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 108.177.97.132, 2404:6800:4008:c00::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|108.177.97.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [  <=>               ]   6.19M  29.9MB/s    in 0.2s    \n",
            "\n",
            "2020-08-17 19:13:13 (29.9 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n",
            "--2020-08-17 19:13:21--  https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.204.102, 74.125.204.139, 74.125.204.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.204.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/drk7usjuseth3anigkao40stapnqjdi3/1597691550000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-17 19:13:22--  https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/drk7usjuseth3anigkao40stapnqjdi3/1597691550000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download\n",
            "Resolving doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)... 108.177.97.132, 2404:6800:4008:c00::84\n",
            "Connecting to doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)|108.177.97.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257793 (252K) [application/x-rar]\n",
            "Saving to: ‘Pillow.rar’\n",
            "\n",
            "Pillow.rar          100%[===================>] 251.75K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2020-08-17 19:13:22 (86.8 MB/s) - ‘Pillow.rar’ saved [257793/257793]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Pillow.rar\n",
            "\n",
            "Creating    Pillow                                                    OK\n",
            "Creating    Pillow/Tests                                              OK\n",
            "Creating    Pillow/Tests/fonts                                        OK\n",
            "Extracting  Pillow/Tests/fonts/FreeMono.ttf                              \b\b\b\b 12%\b\b\b\b 25%\b\b\b\b 38%\b\b\b\b 50%\b\b\b\b 63%\b\b\b\b 76%\b\b\b\b 88%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 842 (delta 197), reused 193 (delta 103), pack-reused 550\u001b[K\n",
            "Receiving objects: 100% (842/842), 475.00 MiB | 15.91 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "Checking out files: 100% (117/117), done.\n",
            "rm: cannot remove 'bird/': No such file or directory\n",
            "rm: cannot remove 'WordLevelGANLoss': No such file or directory\n",
            "Cloning into 'WordLevelGANLoss'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 104 (delta 36), reused 94 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (104/104), 1.22 MiB | 1.37 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXS-eOiZPIQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "550a31c6-d9dc-492a-87d5-feba063afc98"
      },
      "source": [
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py           --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_530.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:02<00:00, 38.3MB/s]\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_530.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS 531\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:438: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  86.42653512954712\n",
            "step :  200 iters_100_time :  81.87114882469177\n",
            "step :  300 iters_100_time :  82.79307985305786\n",
            "step :  400 iters_100_time :  81.7220630645752\n",
            "[531/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 66.71 Time: 366.88s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  48.248491287231445\n",
            "step :  600 iters_100_time :  81.66332507133484\n",
            "step :  700 iters_100_time :  81.77512812614441\n",
            "step :  800 iters_100_time :  81.57255554199219\n",
            "[532/600][442]\n",
            "                    Loss_D: 0.52 Loss_G: 50.26 Time: 362.39s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  13.723678588867188\n",
            "step :  1000 iters_100_time :  81.96216344833374\n",
            "step :  1100 iters_100_time :  81.40045523643494\n",
            "step :  1200 iters_100_time :  81.22218632698059\n",
            "step :  1300 iters_100_time :  81.84681224822998\n",
            "[533/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 65.95 Time: 361.39s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  61.721858978271484\n",
            "step :  1500 iters_100_time :  81.45963191986084\n",
            "step :  1600 iters_100_time :  81.2600646018982\n",
            "step :  1700 iters_100_time :  81.82737135887146\n",
            "[534/600][442]\n",
            "                    Loss_D: 0.39 Loss_G: 62.06 Time: 362.10s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  27.16870927810669\n",
            "step :  1900 iters_100_time :  81.50006914138794\n",
            "step :  2000 iters_100_time :  81.47485542297363\n",
            "step :  2100 iters_100_time :  81.67143058776855\n",
            "step :  2200 iters_100_time :  81.92397165298462\n",
            "[535/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 69.38 Time: 362.07s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  74.07885503768921\n",
            "step :  2400 iters_100_time :  81.45110607147217\n",
            "step :  2500 iters_100_time :  81.32003498077393\n",
            "step :  2600 iters_100_time :  81.62280821800232\n",
            "[536/600][442]\n",
            "                    Loss_D: 1.47 Loss_G: 90.92 Time: 360.98s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  40.509594202041626\n",
            "step :  2800 iters_100_time :  81.65405607223511\n",
            "step :  2900 iters_100_time :  81.38709378242493\n",
            "step :  3000 iters_100_time :  81.21055674552917\n",
            "[537/600][442]\n",
            "                    Loss_D: 0.97 Loss_G: 68.03 Time: 361.72s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  6.083057880401611\n",
            "step :  3200 iters_100_time :  81.87607288360596\n",
            "step :  3300 iters_100_time :  81.4342749118805\n",
            "step :  3400 iters_100_time :  81.86877202987671\n",
            "step :  3500 iters_100_time :  81.38089799880981\n",
            "[538/600][442]\n",
            "                    Loss_D: 0.63 Loss_G: 68.43 Time: 362.58s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  53.48348784446716\n",
            "step :  3700 iters_100_time :  81.87547135353088\n",
            "step :  3800 iters_100_time :  81.8402943611145\n",
            "step :  3900 iters_100_time :  82.1873664855957\n",
            "[539/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 57.44 Time: 363.21s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  19.168551683425903\n",
            "step :  4100 iters_100_time :  81.50062274932861\n",
            "step :  4200 iters_100_time :  82.15031027793884\n",
            "step :  4300 iters_100_time :  81.5107626914978\n",
            "step :  4400 iters_100_time :  81.71755480766296\n",
            "[540/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 61.40 Time: 362.81s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  68.09593439102173\n",
            "step :  4600 iters_100_time :  81.55255699157715\n",
            "step :  4700 iters_100_time :  81.64245104789734\n",
            "step :  4800 iters_100_time :  82.20198345184326\n",
            "[541/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 67.41 Time: 365.03s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  31.63834309577942\n",
            "step :  5000 iters_100_time :  82.25623226165771\n",
            "step :  5000 iters_5000_time :  113.89466190338135\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.812157869338989\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.951376914978027\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  234.98924851417542\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  5100 iters_100_time :  376.8024082183838\n",
            "step :  5200 iters_100_time :  82.23040795326233\n",
            "step :  5300 iters_100_time :  82.59576368331909\n",
            "[542/600][442]\n",
            "                    Loss_D: 1.88 Loss_G: 37.63 Time: 658.97s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  80.2415087223053\n",
            "step :  5500 iters_100_time :  81.97448945045471\n",
            "step :  5600 iters_100_time :  81.55759787559509\n",
            "step :  5700 iters_100_time :  82.52757430076599\n",
            "[543/600][442]\n",
            "                    Loss_D: 0.00 Loss_G: 67.72 Time: 364.33s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  45.74999642372131\n",
            "step :  5900 iters_100_time :  81.86067414283752\n",
            "step :  6000 iters_100_time :  81.87857747077942\n",
            "step :  6100 iters_100_time :  82.26115584373474\n",
            "[544/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 58.59 Time: 364.22s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  10.891955375671387\n",
            "step :  6300 iters_100_time :  81.91739988327026\n",
            "step :  6400 iters_100_time :  82.17048597335815\n",
            "step :  6500 iters_100_time :  82.001056432724\n",
            "step :  6600 iters_100_time :  82.18347191810608\n",
            "[545/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 56.10 Time: 364.26s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  58.86425542831421\n",
            "step :  6800 iters_100_time :  82.11890244483948\n",
            "step :  6900 iters_100_time :  81.74803066253662\n",
            "step :  7000 iters_100_time :  81.87115550041199\n",
            "[546/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 76.03 Time: 363.78s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  24.17559313774109\n",
            "step :  7200 iters_100_time :  81.69222569465637\n",
            "step :  7300 iters_100_time :  81.81706714630127\n",
            "step :  7400 iters_100_time :  82.3029534816742\n",
            "step :  7500 iters_100_time :  82.29266309738159\n",
            "[547/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 65.32 Time: 364.23s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  70.69451308250427\n",
            "step :  7700 iters_100_time :  82.48002171516418\n",
            "step :  7800 iters_100_time :  81.76312398910522\n",
            "step :  7900 iters_100_time :  82.13008975982666\n",
            "[548/600][442]\n",
            "                    Loss_D: 0.46 Loss_G: 86.14 Time: 363.45s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  37.01803135871887\n",
            "step :  8100 iters_100_time :  81.48568296432495\n",
            "step :  8200 iters_100_time :  82.28013849258423\n",
            "step :  8300 iters_100_time :  82.18640041351318\n",
            "[549/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 59.58 Time: 362.85s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.5600764751434326\n",
            "step :  8500 iters_100_time :  81.67808032035828\n",
            "step :  8600 iters_100_time :  82.01184701919556\n",
            "step :  8700 iters_100_time :  82.30897903442383\n",
            "step :  8800 iters_100_time :  81.93583607673645\n",
            "[550/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 68.93 Time: 363.84s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  50.12229633331299\n",
            "step :  9000 iters_100_time :  82.35121321678162\n",
            "step :  9100 iters_100_time :  81.66772770881653\n",
            "step :  9200 iters_100_time :  81.68152236938477\n",
            "[551/600][442]\n",
            "                    Loss_D: 1.89 Loss_G: 44.80 Time: 364.38s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  15.542854070663452\n",
            "step :  9400 iters_100_time :  82.65718150138855\n",
            "step :  9500 iters_100_time :  82.49483823776245\n",
            "step :  9600 iters_100_time :  82.0442430973053\n",
            "step :  9700 iters_100_time :  82.62525796890259\n",
            "[552/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 66.27 Time: 365.18s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  63.7250554561615\n",
            "step :  9900 iters_100_time :  82.4158444404602\n",
            "step :  10000 iters_100_time :  82.47146892547607\n",
            "step :  10000 iters_5000_time :  228.61251211166382\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.878867149353027\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.531009435653687\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  234.69482374191284\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  10100 iters_100_time :  379.25671577453613\n",
            "[553/600][442]\n",
            "                    Loss_D: 0.71 Loss_G: 92.59 Time: 664.19s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  29.97704243659973\n",
            "step :  10300 iters_100_time :  84.5447895526886\n",
            "step :  10400 iters_100_time :  84.9014539718628\n",
            "step :  10500 iters_100_time :  85.06831741333008\n",
            "step :  10600 iters_100_time :  84.90062069892883\n",
            "[554/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 90.60 Time: 377.00s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  79.49931597709656\n",
            "step :  10800 iters_100_time :  85.20412731170654\n",
            "step :  10900 iters_100_time :  85.14251232147217\n",
            "step :  11000 iters_100_time :  85.62160730361938\n",
            "[555/600][442]\n",
            "                    Loss_D: 0.33 Loss_G: 69.85 Time: 378.26s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  43.6797993183136\n",
            "step :  11200 iters_100_time :  85.33109068870544\n",
            "step :  11300 iters_100_time :  85.65345287322998\n",
            "step :  11400 iters_100_time :  84.91048169136047\n",
            "[556/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 78.46 Time: 378.22s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  8.035907506942749\n",
            "step :  11600 iters_100_time :  85.15790915489197\n",
            "step :  11700 iters_100_time :  85.20003294944763\n",
            "step :  11800 iters_100_time :  85.0942771434784\n",
            "step :  11900 iters_100_time :  85.36972904205322\n",
            "[557/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 55.85 Time: 378.58s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  56.997836112976074\n",
            "step :  12100 iters_100_time :  85.02606391906738\n",
            "step :  12200 iters_100_time :  85.76064801216125\n",
            "step :  12300 iters_100_time :  85.80813455581665\n",
            "[558/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 64.41 Time: 379.19s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  21.242774963378906\n",
            "step :  12500 iters_100_time :  85.52183604240417\n",
            "step :  12600 iters_100_time :  85.40640330314636\n",
            "step :  12700 iters_100_time :  85.13583397865295\n",
            "step :  12800 iters_100_time :  85.02368474006653\n",
            "[559/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 62.18 Time: 377.85s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  70.54663491249084\n",
            "step :  13000 iters_100_time :  85.49574112892151\n",
            "step :  13100 iters_100_time :  85.49948000907898\n",
            "step :  13200 iters_100_time :  85.80586910247803\n",
            "[560/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 48.21 Time: 379.02s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  35.11253309249878\n",
            "step :  13400 iters_100_time :  82.2051260471344\n",
            "step :  13500 iters_100_time :  82.0449709892273\n",
            "step :  13600 iters_100_time :  82.54465508460999\n",
            "step :  13700 iters_100_time :  82.477205991745\n",
            "[561/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 71.26 Time: 366.61s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  81.43802642822266\n",
            "step :  13900 iters_100_time :  83.33668518066406\n",
            "step :  14000 iters_100_time :  82.48619961738586\n",
            "step :  14100 iters_100_time :  82.26598262786865\n",
            "[562/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 51.89 Time: 366.03s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  47.17152452468872\n",
            "step :  14300 iters_100_time :  82.86597657203674\n",
            "step :  14400 iters_100_time :  82.08281993865967\n",
            "step :  14500 iters_100_time :  82.47588014602661\n",
            "[563/600][442]\n",
            "                    Loss_D: 0.52 Loss_G: 60.60 Time: 365.45s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  12.655670881271362\n",
            "step :  14700 iters_100_time :  82.16253924369812\n",
            "step :  14800 iters_100_time :  82.8281090259552\n",
            "step :  14900 iters_100_time :  82.5429298877716\n",
            "step :  15000 iters_100_time :  82.35262870788574\n",
            "step :  15000 iters_5000_time :  342.5421097278595\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.836469650268555\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.346680402755737\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  220.53754878044128\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[564/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 77.86 Time: 644.96s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  60.43973159790039\n",
            "step :  15200 iters_100_time :  83.12610864639282\n",
            "step :  15300 iters_100_time :  82.16626691818237\n",
            "step :  15400 iters_100_time :  82.97224736213684\n",
            "[565/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 55.94 Time: 366.61s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  25.965224742889404\n",
            "step :  15600 iters_100_time :  82.53883099555969\n",
            "step :  15700 iters_100_time :  82.66607856750488\n",
            "step :  15800 iters_100_time :  82.95591330528259\n",
            "step :  15900 iters_100_time :  82.07266688346863\n",
            "[566/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 57.48 Time: 367.12s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  73.52453875541687\n",
            "step :  16100 iters_100_time :  83.32774901390076\n",
            "step :  16200 iters_100_time :  82.6656801700592\n",
            "step :  16300 iters_100_time :  82.85474896430969\n",
            "[567/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 72.94 Time: 367.87s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  38.97308325767517\n",
            "step :  16500 iters_100_time :  82.49790096282959\n",
            "step :  16600 iters_100_time :  83.42496728897095\n",
            "step :  16700 iters_100_time :  83.01037383079529\n",
            "[568/600][442]\n",
            "                    Loss_D: 1.23 Loss_G: 59.05 Time: 367.67s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  4.078636884689331\n",
            "step :  16900 iters_100_time :  81.97344756126404\n",
            "step :  17000 iters_100_time :  82.9239251613617\n",
            "step :  17100 iters_100_time :  82.72708654403687\n",
            "step :  17200 iters_100_time :  82.5365264415741\n",
            "[569/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 82.38 Time: 366.29s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  52.007949113845825\n",
            "step :  17400 iters_100_time :  83.10577940940857\n",
            "step :  17500 iters_100_time :  82.5904951095581\n",
            "step :  17600 iters_100_time :  82.93560647964478\n",
            "[570/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 61.51 Time: 366.74s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  18.36433458328247\n",
            "step :  17800 iters_100_time :  83.13015341758728\n",
            "step :  17900 iters_100_time :  82.93998718261719\n",
            "step :  18000 iters_100_time :  82.95286679267883\n",
            "step :  18100 iters_100_time :  83.2650842666626\n",
            "[571/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 63.64 Time: 368.94s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  65.58350920677185\n",
            "step :  18300 iters_100_time :  83.16782069206238\n",
            "step :  18400 iters_100_time :  83.02857160568237\n",
            "step :  18500 iters_100_time :  82.73045802116394\n",
            "[572/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 62.11 Time: 367.67s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  30.343490839004517\n",
            "step :  18700 iters_100_time :  82.57098412513733\n",
            "step :  18800 iters_100_time :  83.01729393005371\n",
            "step :  18900 iters_100_time :  81.79777646064758\n",
            "step :  19000 iters_100_time :  82.84576630592346\n",
            "[573/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 53.76 Time: 365.61s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  78.20409679412842\n",
            "step :  19200 iters_100_time :  82.50724172592163\n",
            "step :  19300 iters_100_time :  82.60273814201355\n",
            "step :  19400 iters_100_time :  82.46843910217285\n",
            "[574/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 58.20 Time: 365.54s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  43.600114822387695\n",
            "step :  19600 iters_100_time :  82.44557189941406\n",
            "step :  19700 iters_100_time :  82.76492142677307\n",
            "step :  19800 iters_100_time :  82.97541761398315\n",
            "[575/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 67.97 Time: 366.33s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  9.403921365737915\n",
            "step :  20000 iters_100_time :  82.67136311531067\n",
            "step :  20000 iters_5000_time :  92.07536482810974\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.759279727935791\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.800128698349\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  217.61359548568726\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  20100 iters_100_time :  359.01999020576477\n",
            "step :  20200 iters_100_time :  82.43829560279846\n",
            "step :  20300 iters_100_time :  82.83651971817017\n",
            "[576/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 60.13 Time: 643.53s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  56.652873039245605\n",
            "step :  20500 iters_100_time :  82.66497611999512\n",
            "step :  20600 iters_100_time :  83.07340216636658\n",
            "step :  20700 iters_100_time :  82.63475227355957\n",
            "[577/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 65.90 Time: 367.14s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  22.054509162902832\n",
            "step :  20900 iters_100_time :  82.38403010368347\n",
            "step :  21000 iters_100_time :  83.1716091632843\n",
            "step :  21100 iters_100_time :  82.59278059005737\n",
            "step :  21200 iters_100_time :  82.54106307029724\n",
            "[578/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 71.53 Time: 366.70s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  70.52687072753906\n",
            "step :  21400 iters_100_time :  82.31156945228577\n",
            "step :  21500 iters_100_time :  83.07591533660889\n",
            "step :  21600 iters_100_time :  82.86961317062378\n",
            "[579/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 68.38 Time: 367.12s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  35.1951847076416\n",
            "step :  21800 iters_100_time :  82.74745512008667\n",
            "step :  21900 iters_100_time :  82.49199604988098\n",
            "step :  22000 iters_100_time :  83.37996125221252\n",
            "step :  22100 iters_100_time :  81.89685225486755\n",
            "[580/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 67.70 Time: 366.11s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  84.02312350273132\n",
            "step :  22300 iters_100_time :  82.88921809196472\n",
            "step :  22400 iters_100_time :  82.94563317298889\n",
            "step :  22500 iters_100_time :  82.77928352355957\n",
            "[581/600][442]\n",
            "                    Loss_D: 0.84 Loss_G: 63.20 Time: 367.83s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  48.92751932144165\n",
            "step :  22700 iters_100_time :  82.43668150901794\n",
            "step :  22800 iters_100_time :  83.71687960624695\n",
            "step :  22900 iters_100_time :  83.00155329704285\n",
            "[582/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 87.98 Time: 367.59s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  14.453393697738647\n",
            "step :  23100 iters_100_time :  82.947012424469\n",
            "step :  23200 iters_100_time :  83.45515751838684\n",
            "step :  23300 iters_100_time :  83.07746767997742\n",
            "step :  23400 iters_100_time :  82.67020893096924\n",
            "[583/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 48.03 Time: 368.61s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  62.5807101726532\n",
            "step :  23600 iters_100_time :  82.43925642967224\n",
            "step :  23700 iters_100_time :  83.12936544418335\n",
            "step :  23800 iters_100_time :  83.11669421195984\n",
            "[584/600][442]\n",
            "                    Loss_D: 0.21 Loss_G: 58.73 Time: 367.61s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  27.541211128234863\n",
            "step :  24000 iters_100_time :  82.59360218048096\n",
            "step :  24100 iters_100_time :  83.19292974472046\n",
            "step :  24200 iters_100_time :  83.38269758224487\n",
            "step :  24300 iters_100_time :  82.5933609008789\n",
            "[585/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 70.74 Time: 367.66s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  75.78235292434692\n",
            "step :  24500 iters_100_time :  83.13150358200073\n",
            "step :  24600 iters_100_time :  82.61174368858337\n",
            "step :  24700 iters_100_time :  83.30143785476685\n",
            "[586/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 54.70 Time: 368.08s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  40.54157519340515\n",
            "step :  24900 iters_100_time :  83.04959011077881\n",
            "step :  25000 iters_100_time :  82.78263187408447\n",
            "step :  25000 iters_5000_time :  206.37394094467163\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.713414430618286\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.660008430480957\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  211.0828504562378\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  352.17494320869446\n",
            "[587/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 59.80 Time: 637.69s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  6.365351915359497\n",
            "step :  25300 iters_100_time :  82.62237858772278\n",
            "step :  25400 iters_100_time :  83.363529920578\n",
            "step :  25500 iters_100_time :  83.1743893623352\n",
            "step :  25600 iters_100_time :  82.8183856010437\n",
            "[588/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 50.74 Time: 368.41s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  54.95444297790527\n",
            "step :  25800 iters_100_time :  83.5920045375824\n",
            "step :  25900 iters_100_time :  82.9933249950409\n",
            "step :  26000 iters_100_time :  82.77499842643738\n",
            "[589/600][442]\n",
            "                    Loss_D: 0.68 Loss_G: 66.43 Time: 369.59s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  19.63164258003235\n",
            "step :  26200 iters_100_time :  83.21123814582825\n",
            "step :  26300 iters_100_time :  83.36791181564331\n",
            "step :  26400 iters_100_time :  83.27890682220459\n",
            "step :  26500 iters_100_time :  83.63490962982178\n",
            "[590/600][442]\n",
            "                    Loss_D: 0.45 Loss_G: 66.62 Time: 370.67s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  26600 iters_100_time :  71.29400539398193\n",
            "step :  26700 iters_100_time :  86.99056005477905\n",
            "step :  26800 iters_100_time :  86.78689050674438\n",
            "step :  26900 iters_100_time :  86.06148266792297\n",
            "[591/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 47.50 Time: 385.03s\n",
            "num_batches :  442\n",
            "step :  27000 iters_100_time :  33.86566996574402\n",
            "step :  27100 iters_100_time :  86.93916749954224\n",
            "step :  27200 iters_100_time :  86.45552515983582\n",
            "step :  27300 iters_100_time :  86.99233794212341\n",
            "step :  27400 iters_100_time :  86.66576266288757\n",
            "[592/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 74.43 Time: 384.72s\n",
            "num_batches :  442\n",
            "step :  27500 iters_100_time :  83.77570819854736\n",
            "step :  27600 iters_100_time :  86.88608384132385\n",
            "step :  27700 iters_100_time :  86.94351243972778\n",
            "step :  27800 iters_100_time :  86.83837962150574\n",
            "[593/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 63.23 Time: 384.41s\n",
            "num_batches :  442\n",
            "step :  27900 iters_100_time :  47.64254403114319\n",
            "step :  28000 iters_100_time :  86.07486653327942\n",
            "step :  28100 iters_100_time :  86.93625283241272\n",
            "step :  28200 iters_100_time :  86.9988465309143\n",
            "[594/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 81.26 Time: 383.50s\n",
            "num_batches :  442\n",
            "step :  28300 iters_100_time :  11.788721323013306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFHcQmD6nzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}