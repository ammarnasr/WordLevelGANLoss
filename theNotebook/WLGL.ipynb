{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WLGL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4bb0678c-6e63-4031-d6ab-6ac8b6893f46"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Aug 13 10:02:43 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a821b704-9544-4ad8-be4c-1645c34cc7c9"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n",
        "#clone repo AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git\n",
        "\n",
        "#Changing Working dirctory to data\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "#Downloads birds.zip (6.19M) , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/\n",
        "\n",
        "#Changing Working dirctory to code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "#Download Pillow.rar (251.75K), , Extract it , and remove unnesscery files\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar\n",
        "\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "!mv /content/CUB-Attn-GAN/theModel/text_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "!rm -r /content/CUB-Attn-GAN/\n",
        "\n",
        "#Changing Working dirctory to birds\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!cp '/content/drive/My Drive/cub/CUB_200_2011.tgz' '/content/AttnGAN/data/birds/'\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz\n",
        "\n",
        "os.chdir('/content')\n",
        "!rm -r WordLevelGANLoss\n",
        "!git clone https://github.com/ammarnasr/WordLevelGANLoss.git\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/utils.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/losses.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/trainer.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/config.py /content/AttnGAN/code/miscc/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/datasets.py /content/AttnGAN/code/\n",
        "!mv /content/WordLevelGANLoss/theCode/GAN/bird_attn2.yml /content/AttnGAN/code/cfg/\n",
        "\n",
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netG_epoch_470.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/cubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 12.68 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "--2020-08-13 10:07:00--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.79.100, 173.194.79.102, 173.194.79.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.79.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2t5683d2fg916msato6dcnl2rldldi2n/1597313250000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-13 10:07:31--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2t5683d2fg916msato6dcnl2rldldi2n/1597313250000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [ <=>                ]   6.19M  36.1MB/s    in 0.2s    \n",
            "\n",
            "2020-08-13 10:07:31 (36.1 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n",
            "--2020-08-13 10:07:38--  https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111\n",
            "Resolving docs.google.com (docs.google.com)... 108.177.126.102, 108.177.126.138, 108.177.126.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|108.177.126.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rio6n6dbu0cm2qb1kil1bh426i0tlbon/1597313250000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-08-13 10:07:39--  https://doc-04-6c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rio6n6dbu0cm2qb1kil1bh426i0tlbon/1597313250000/17309505201871794426/*/1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111?e=download\n",
            "Resolving doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)... 172.217.218.132, 2a00:1450:4013:c08::84\n",
            "Connecting to doc-04-6c-docs.googleusercontent.com (doc-04-6c-docs.googleusercontent.com)|172.217.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257793 (252K) [application/x-rar]\n",
            "Saving to: ‘Pillow.rar’\n",
            "\n",
            "Pillow.rar          100%[===================>] 251.75K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2020-08-13 10:07:39 (136 MB/s) - ‘Pillow.rar’ saved [257793/257793]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Pillow.rar\n",
            "\n",
            "Creating    Pillow                                                    OK\n",
            "Creating    Pillow/Tests                                              OK\n",
            "Creating    Pillow/Tests/fonts                                        OK\n",
            "Extracting  Pillow/Tests/fonts/FreeMono.ttf                              \b\b\b\b 12%\b\b\b\b 25%\b\b\b\b 38%\b\b\b\b 50%\b\b\b\b 63%\b\b\b\b 76%\b\b\b\b 88%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 292, done.\u001b[K\n",
            "remote: Counting objects: 100% (292/292), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 842 (delta 197), reused 193 (delta 103), pack-reused 550\u001b[K\n",
            "Receiving objects: 100% (842/842), 475.00 MiB | 24.32 MiB/s, done.\n",
            "Resolving deltas: 100% (497/497), done.\n",
            "Checking out files: 100% (117/117), done.\n",
            "rm: cannot remove 'bird/': No such file or directory\n",
            "rm: cannot remove 'WordLevelGANLoss': No such file or directory\n",
            "Cloning into 'WordLevelGANLoss'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 90 (delta 30), reused 80 (delta 23), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXS-eOiZPIQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "009fcf23-3e2f-46f2-ed73-23c71fd3c740"
      },
      "source": [
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py           --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_390.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:257: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/models/inception.py:77: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
            "  ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:01<00:00, 94.1MB/s]\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_390.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "START EPOCH IS 391\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())\n",
            "/content/AttnGAN/code/trainer.py:438: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  avg_p.mul_(0.999).add_(0.001, p.data)\n",
            "step :  100 iters_100_time :  80.71712613105774\n",
            "step :  200 iters_100_time :  76.00285840034485\n",
            "step :  300 iters_100_time :  74.63423085212708\n",
            "step :  400 iters_100_time :  75.9318675994873\n",
            "[391/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 59.69 Time: 339.07s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  44.641308069229126\n",
            "step :  600 iters_100_time :  76.16681337356567\n",
            "step :  700 iters_100_time :  75.00938820838928\n",
            "step :  800 iters_100_time :  75.81900596618652\n",
            "[392/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 61.08 Time: 335.27s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  12.688026666641235\n",
            "step :  1000 iters_100_time :  76.06690692901611\n",
            "step :  1100 iters_100_time :  75.97885131835938\n",
            "step :  1200 iters_100_time :  76.07870960235596\n",
            "step :  1300 iters_100_time :  75.9391520023346\n",
            "[393/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 46.46 Time: 337.30s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  56.81325340270996\n",
            "step :  1500 iters_100_time :  75.88742995262146\n",
            "step :  1600 iters_100_time :  75.95840406417847\n",
            "step :  1700 iters_100_time :  76.01263380050659\n",
            "[394/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 68.91 Time: 336.02s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  25.14164137840271\n",
            "step :  1900 iters_100_time :  76.06403493881226\n",
            "step :  2000 iters_100_time :  75.30288314819336\n",
            "step :  2100 iters_100_time :  75.92038464546204\n",
            "step :  2200 iters_100_time :  75.60854125022888\n",
            "[395/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 62.91 Time: 335.97s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  68.96182751655579\n",
            "step :  2400 iters_100_time :  76.03856039047241\n",
            "step :  2500 iters_100_time :  75.88159823417664\n",
            "step :  2600 iters_100_time :  75.9872522354126\n",
            "[396/600][442]\n",
            "                    Loss_D: 0.74 Loss_G: 39.86 Time: 336.69s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  37.27183675765991\n",
            "step :  2800 iters_100_time :  75.56087803840637\n",
            "step :  2900 iters_100_time :  76.0131254196167\n",
            "step :  3000 iters_100_time :  75.76517629623413\n",
            "[397/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 54.66 Time: 336.43s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  5.249739170074463\n",
            "step :  3200 iters_100_time :  75.27619361877441\n",
            "step :  3300 iters_100_time :  75.88414096832275\n",
            "step :  3400 iters_100_time :  75.50788688659668\n",
            "step :  3500 iters_100_time :  75.86885333061218\n",
            "[398/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 59.43 Time: 335.34s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  48.997180461883545\n",
            "step :  3700 iters_100_time :  75.42023944854736\n",
            "step :  3800 iters_100_time :  76.2357017993927\n",
            "step :  3900 iters_100_time :  75.04447722434998\n",
            "[399/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 64.62 Time: 335.37s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  17.43914794921875\n",
            "step :  4100 iters_100_time :  75.27261877059937\n",
            "step :  4200 iters_100_time :  75.93221497535706\n",
            "step :  4300 iters_100_time :  75.30530500411987\n",
            "step :  4400 iters_100_time :  76.1074960231781\n",
            "[400/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 54.39 Time: 335.36s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  61.38142442703247\n",
            "step :  4600 iters_100_time :  75.83144497871399\n",
            "step :  4700 iters_100_time :  75.95921444892883\n",
            "step :  4800 iters_100_time :  75.64109492301941\n",
            "[401/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 53.78 Time: 336.51s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  29.759830713272095\n",
            "step :  5000 iters_100_time :  75.9329583644867\n",
            "step :  5000 iters_5000_time :  105.69285798072815\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.05724835395813\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.709631204605103\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  205.60563206672668\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  5100 iters_100_time :  335.46968722343445\n",
            "step :  5200 iters_100_time :  75.56163120269775\n",
            "step :  5300 iters_100_time :  75.72774600982666\n",
            "[402/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 55.55 Time: 595.64s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  73.61172604560852\n",
            "step :  5500 iters_100_time :  75.42047715187073\n",
            "step :  5600 iters_100_time :  75.65858507156372\n",
            "step :  5700 iters_100_time :  75.94534492492676\n",
            "[403/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 62.61 Time: 336.25s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  41.5199294090271\n",
            "step :  5900 iters_100_time :  75.5981662273407\n",
            "step :  6000 iters_100_time :  76.03930163383484\n",
            "step :  6100 iters_100_time :  75.89402532577515\n",
            "[404/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 66.66 Time: 336.04s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  10.08941650390625\n",
            "step :  6300 iters_100_time :  75.89972019195557\n",
            "step :  6400 iters_100_time :  76.1115996837616\n",
            "step :  6500 iters_100_time :  75.2425549030304\n",
            "step :  6600 iters_100_time :  75.86002469062805\n",
            "[405/600][442]\n",
            "                    Loss_D: 0.97 Loss_G: 68.28 Time: 336.46s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  53.97494626045227\n",
            "step :  6800 iters_100_time :  75.58103036880493\n",
            "step :  6900 iters_100_time :  76.20003914833069\n",
            "step :  7000 iters_100_time :  75.877117395401\n",
            "[406/600][442]\n",
            "                    Loss_D: 0.49 Loss_G: 50.44 Time: 336.44s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  21.90880274772644\n",
            "step :  7200 iters_100_time :  76.29463982582092\n",
            "step :  7300 iters_100_time :  75.7719955444336\n",
            "step :  7400 iters_100_time :  76.15886640548706\n",
            "step :  7500 iters_100_time :  75.74828624725342\n",
            "[407/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 56.81 Time: 336.94s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  65.70961928367615\n",
            "step :  7700 iters_100_time :  75.92408657073975\n",
            "step :  7800 iters_100_time :  75.82072043418884\n",
            "step :  7900 iters_100_time :  76.14075636863708\n",
            "[408/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 46.09 Time: 336.58s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  33.61672115325928\n",
            "step :  8100 iters_100_time :  76.01938915252686\n",
            "step :  8200 iters_100_time :  76.18948101997375\n",
            "step :  8300 iters_100_time :  75.71129250526428\n",
            "[409/600][442]\n",
            "                    Loss_D: 1.24 Loss_G: 59.75 Time: 336.11s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.1585052013397217\n",
            "step :  8500 iters_100_time :  76.332102060318\n",
            "step :  8600 iters_100_time :  76.02794909477234\n",
            "step :  8700 iters_100_time :  76.02276873588562\n",
            "step :  8800 iters_100_time :  75.46714425086975\n",
            "[410/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 61.45 Time: 336.97s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  46.63049387931824\n",
            "step :  9000 iters_100_time :  75.80238723754883\n",
            "step :  9100 iters_100_time :  75.9046950340271\n",
            "step :  9200 iters_100_time :  75.79513740539551\n",
            "[411/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 74.46 Time: 337.06s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  14.046826601028442\n",
            "step :  9400 iters_100_time :  75.57355213165283\n",
            "step :  9500 iters_100_time :  75.84016466140747\n",
            "step :  9600 iters_100_time :  76.27098274230957\n",
            "step :  9700 iters_100_time :  75.98293805122375\n",
            "[412/600][442]\n",
            "                    Loss_D: 1.23 Loss_G: 49.95 Time: 336.24s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  58.146841287612915\n",
            "step :  9900 iters_100_time :  75.50986647605896\n",
            "step :  10000 iters_100_time :  76.0892322063446\n",
            "step :  10000 iters_5000_time :  209.74604988098145\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  6.9085023403167725\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.30187749862671\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  189.23752117156982\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  10100 iters_100_time :  318.1825397014618\n",
            "[413/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 57.88 Time: 578.79s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  26.159141302108765\n",
            "step :  10300 iters_100_time :  75.4500961303711\n",
            "step :  10400 iters_100_time :  76.42161870002747\n",
            "step :  10500 iters_100_time :  76.14555144309998\n",
            "step :  10600 iters_100_time :  76.11408758163452\n",
            "[414/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 64.43 Time: 336.96s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  70.55281949043274\n",
            "step :  10800 iters_100_time :  75.57301211357117\n",
            "step :  10900 iters_100_time :  76.2376799583435\n",
            "step :  11000 iters_100_time :  75.83583974838257\n",
            "[415/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 52.92 Time: 336.65s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  38.56882381439209\n",
            "step :  11200 iters_100_time :  76.14545965194702\n",
            "step :  11300 iters_100_time :  75.7388162612915\n",
            "step :  11400 iters_100_time :  76.35068368911743\n",
            "[416/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 57.15 Time: 337.08s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.975375413894653\n",
            "step :  11600 iters_100_time :  75.7908284664154\n",
            "step :  11700 iters_100_time :  75.85124397277832\n",
            "step :  11800 iters_100_time :  76.07138681411743\n",
            "step :  11900 iters_100_time :  75.9811658859253\n",
            "[417/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 56.41 Time: 336.92s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  50.64257097244263\n",
            "step :  12100 iters_100_time :  75.9714081287384\n",
            "step :  12200 iters_100_time :  76.09729528427124\n",
            "step :  12300 iters_100_time :  76.11088585853577\n",
            "[418/600][442]\n",
            "                    Loss_D: 0.36 Loss_G: 61.68 Time: 337.17s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  18.748053789138794\n",
            "step :  12500 iters_100_time :  76.20435667037964\n",
            "step :  12600 iters_100_time :  76.07988452911377\n",
            "step :  12700 iters_100_time :  76.55342745780945\n",
            "step :  12800 iters_100_time :  75.96886491775513\n",
            "[419/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 57.63 Time: 337.76s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  63.03562879562378\n",
            "step :  13000 iters_100_time :  76.0227746963501\n",
            "step :  13100 iters_100_time :  76.21410703659058\n",
            "step :  13200 iters_100_time :  76.03638005256653\n",
            "[420/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 84.68 Time: 337.66s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  31.44850254058838\n",
            "step :  13400 iters_100_time :  75.99529004096985\n",
            "step :  13500 iters_100_time :  75.93140530586243\n",
            "step :  13600 iters_100_time :  76.16766571998596\n",
            "step :  13700 iters_100_time :  76.38632726669312\n",
            "[421/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 55.68 Time: 337.98s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  74.9479591846466\n",
            "step :  13900 iters_100_time :  76.5904688835144\n",
            "step :  14000 iters_100_time :  76.54325222969055\n",
            "step :  14100 iters_100_time :  76.45448350906372\n",
            "[422/600][442]\n",
            "                    Loss_D: 0.83 Loss_G: 46.35 Time: 338.60s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  44.050602197647095\n",
            "step :  14300 iters_100_time :  76.74852871894836\n",
            "step :  14400 iters_100_time :  76.15537333488464\n",
            "step :  14500 iters_100_time :  76.81164598464966\n",
            "[423/600][442]\n",
            "                    Loss_D: 0.40 Loss_G: 59.89 Time: 340.28s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  11.24448013305664\n",
            "step :  14700 iters_100_time :  77.03135871887207\n",
            "step :  14800 iters_100_time :  76.58941125869751\n",
            "step :  14900 iters_100_time :  77.41473436355591\n",
            "step :  15000 iters_100_time :  76.9383111000061\n",
            "step :  15000 iters_5000_time :  319.21849060058594\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.549475193023682\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.571229934692383\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  229.81396675109863\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[424/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 68.48 Time: 629.48s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  56.656508922576904\n",
            "step :  15200 iters_100_time :  76.40787887573242\n",
            "step :  15300 iters_100_time :  77.2791485786438\n",
            "step :  15400 iters_100_time :  77.1495053768158\n",
            "[425/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 53.80 Time: 341.79s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  23.63522243499756\n",
            "step :  15600 iters_100_time :  77.20919895172119\n",
            "step :  15700 iters_100_time :  77.07068276405334\n",
            "step :  15800 iters_100_time :  77.4221510887146\n",
            "step :  15900 iters_100_time :  77.26911544799805\n",
            "[426/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 58.18 Time: 342.27s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  68.59483075141907\n",
            "step :  16100 iters_100_time :  76.50089621543884\n",
            "step :  16200 iters_100_time :  77.27415180206299\n",
            "step :  16300 iters_100_time :  77.16836953163147\n",
            "[427/600][442]\n",
            "                    Loss_D: 0.54 Loss_G: 69.62 Time: 341.66s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  36.253936529159546\n",
            "step :  16500 iters_100_time :  77.34355854988098\n",
            "step :  16600 iters_100_time :  77.2056314945221\n",
            "step :  16700 iters_100_time :  77.20832014083862\n",
            "[428/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 71.58 Time: 342.84s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.8309991359710693\n",
            "step :  16900 iters_100_time :  77.56039357185364\n",
            "step :  17000 iters_100_time :  77.24574375152588\n",
            "step :  17100 iters_100_time :  77.44419693946838\n",
            "step :  17200 iters_100_time :  77.5787045955658\n",
            "[429/600][442]\n",
            "                    Loss_D: 1.16 Loss_G: 68.72 Time: 343.31s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  48.494952917099\n",
            "step :  17400 iters_100_time :  77.57104992866516\n",
            "step :  17500 iters_100_time :  77.30088138580322\n",
            "step :  17600 iters_100_time :  77.22522592544556\n",
            "[430/600][442]\n",
            "                    Loss_D: 0.66 Loss_G: 86.08 Time: 343.22s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  16.73119306564331\n",
            "step :  17800 iters_100_time :  77.29700350761414\n",
            "step :  17900 iters_100_time :  76.99622893333435\n",
            "step :  18000 iters_100_time :  76.99440336227417\n",
            "step :  18100 iters_100_time :  77.30249500274658\n",
            "[431/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 73.49 Time: 343.07s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  61.105944871902466\n",
            "step :  18300 iters_100_time :  77.29047584533691\n",
            "step :  18400 iters_100_time :  77.62848901748657\n",
            "step :  18500 iters_100_time :  77.86936688423157\n",
            "[432/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 54.30 Time: 344.17s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  28.559375047683716\n",
            "step :  18700 iters_100_time :  77.61706638336182\n",
            "step :  18800 iters_100_time :  77.13916563987732\n",
            "step :  18900 iters_100_time :  77.6164915561676\n",
            "step :  19000 iters_100_time :  77.65978193283081\n",
            "[433/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 56.01 Time: 343.77s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  73.98341083526611\n",
            "step :  19200 iters_100_time :  77.32410454750061\n",
            "step :  19300 iters_100_time :  77.9201729297638\n",
            "step :  19400 iters_100_time :  77.9866144657135\n",
            "[434/600][442]\n",
            "                    Loss_D: 0.27 Loss_G: 58.53 Time: 345.41s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  41.22545886039734\n",
            "step :  19600 iters_100_time :  78.02708458900452\n",
            "step :  19700 iters_100_time :  78.1295268535614\n",
            "step :  19800 iters_100_time :  77.8109118938446\n",
            "[435/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 76.61 Time: 345.52s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  8.80510401725769\n",
            "step :  20000 iters_100_time :  77.56559181213379\n",
            "step :  20000 iters_5000_time :  86.37077355384827\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.772030353546143\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  29.619189500808716\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  227.72708177566528\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  20100 iters_100_time :  364.97647356987\n",
            "step :  20200 iters_100_time :  77.58136010169983\n",
            "step :  20300 iters_100_time :  78.02423214912415\n",
            "[436/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 79.29 Time: 632.06s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  53.889880418777466\n",
            "step :  20500 iters_100_time :  77.27622079849243\n",
            "step :  20600 iters_100_time :  77.02943015098572\n",
            "step :  20700 iters_100_time :  77.43427872657776\n",
            "[437/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 64.76 Time: 343.34s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  20.489022731781006\n",
            "step :  20900 iters_100_time :  77.4230227470398\n",
            "step :  21000 iters_100_time :  77.70373606681824\n",
            "step :  21100 iters_100_time :  77.45908331871033\n",
            "step :  21200 iters_100_time :  77.57272839546204\n",
            "[438/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 82.43 Time: 343.78s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  66.2785484790802\n",
            "step :  21400 iters_100_time :  77.82011580467224\n",
            "step :  21500 iters_100_time :  77.7374804019928\n",
            "step :  21600 iters_100_time :  78.0560405254364\n",
            "[439/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 57.09 Time: 345.45s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  33.175541162490845\n",
            "step :  21800 iters_100_time :  77.72172856330872\n",
            "step :  21900 iters_100_time :  77.89989352226257\n",
            "step :  22000 iters_100_time :  77.95948696136475\n",
            "step :  22100 iters_100_time :  78.04854965209961\n",
            "[440/600][442]\n",
            "                    Loss_D: 0.54 Loss_G: 68.62 Time: 345.34s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  78.55593132972717\n",
            "step :  22300 iters_100_time :  77.53867173194885\n",
            "step :  22400 iters_100_time :  77.94276738166809\n",
            "step :  22500 iters_100_time :  77.27327227592468\n",
            "[441/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 50.48 Time: 344.51s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  45.79785203933716\n",
            "step :  22700 iters_100_time :  77.79807567596436\n",
            "step :  22800 iters_100_time :  77.82837533950806\n",
            "step :  22900 iters_100_time :  77.36621618270874\n",
            "[442/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 56.10 Time: 345.28s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  13.117510557174683\n",
            "step :  23100 iters_100_time :  77.49303078651428\n",
            "step :  23200 iters_100_time :  77.8294563293457\n",
            "step :  23300 iters_100_time :  77.44416618347168\n",
            "step :  23400 iters_100_time :  77.83390641212463\n",
            "[443/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 62.68 Time: 344.37s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  57.956697940826416\n",
            "step :  23600 iters_100_time :  77.36296391487122\n",
            "step :  23700 iters_100_time :  77.80005598068237\n",
            "step :  23800 iters_100_time :  77.48275446891785\n",
            "[444/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 49.66 Time: 344.54s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  25.410552263259888\n",
            "step :  24000 iters_100_time :  77.7175018787384\n",
            "step :  24100 iters_100_time :  77.44954824447632\n",
            "step :  24200 iters_100_time :  77.73934483528137\n",
            "step :  24300 iters_100_time :  77.01859259605408\n",
            "[445/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 65.87 Time: 343.40s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  70.84122157096863\n",
            "step :  24500 iters_100_time :  77.17274808883667\n",
            "step :  24600 iters_100_time :  77.45758271217346\n",
            "step :  24700 iters_100_time :  77.6031129360199\n",
            "[446/600][442]\n",
            "                    Loss_D: 0.33 Loss_G: 53.43 Time: 343.86s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  37.53405261039734\n",
            "step :  24900 iters_100_time :  77.86752033233643\n",
            "step :  25000 iters_100_time :  77.99465608596802\n",
            "step :  25000 iters_5000_time :  193.39634680747986\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.1619603633880615\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  26.83070969581604\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  206.22092366218567\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  340.53755235671997\n",
            "[447/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 70.27 Time: 609.03s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  5.579230546951294\n",
            "step :  25300 iters_100_time :  80.94742035865784\n",
            "step :  25400 iters_100_time :  78.83574962615967\n",
            "step :  25500 iters_100_time :  80.23418235778809\n",
            "step :  25600 iters_100_time :  80.27106857299805\n",
            "[448/600][442]\n",
            "                    Loss_D: 1.17 Loss_G: 83.61 Time: 354.25s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  51.626596450805664\n",
            "step :  25800 iters_100_time :  80.6288993358612\n",
            "step :  25900 iters_100_time :  79.28766202926636\n",
            "step :  26000 iters_100_time :  79.41350746154785\n",
            "[449/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 46.54 Time: 354.08s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  19.249696016311646\n",
            "step :  26200 iters_100_time :  78.69709420204163\n",
            "step :  26300 iters_100_time :  79.97327041625977\n",
            "step :  26400 iters_100_time :  80.2713098526001\n",
            "step :  26500 iters_100_time :  79.18768882751465\n",
            "[450/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 53.96 Time: 354.06s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  26600 iters_100_time :  62.76267600059509\n",
            "step :  26700 iters_100_time :  77.8687539100647\n",
            "step :  26800 iters_100_time :  77.37661290168762\n",
            "step :  26900 iters_100_time :  77.2907645702362\n",
            "[451/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 48.91 Time: 344.76s\n",
            "num_batches :  442\n",
            "step :  27000 iters_100_time :  30.125553131103516\n",
            "step :  27100 iters_100_time :  77.74991345405579\n",
            "step :  27200 iters_100_time :  77.49304366111755\n",
            "step :  27300 iters_100_time :  78.57142066955566\n",
            "step :  27400 iters_100_time :  77.54247117042542\n",
            "[452/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 87.05 Time: 344.94s\n",
            "num_batches :  442\n",
            "step :  27500 iters_100_time :  75.69969630241394\n",
            "step :  27600 iters_100_time :  77.41537070274353\n",
            "step :  27700 iters_100_time :  78.29108762741089\n",
            "step :  27800 iters_100_time :  77.80768632888794\n",
            "[453/600][442]\n",
            "                    Loss_D: 0.72 Loss_G: 64.13 Time: 345.94s\n",
            "num_batches :  442\n",
            "step :  27900 iters_100_time :  42.34641718864441\n",
            "step :  28000 iters_100_time :  78.08157753944397\n",
            "step :  28100 iters_100_time :  77.8854124546051\n",
            "step :  28200 iters_100_time :  77.88525748252869\n",
            "[454/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 64.93 Time: 345.53s\n",
            "num_batches :  442\n",
            "step :  28300 iters_100_time :  10.188456296920776\n",
            "step :  28400 iters_100_time :  77.78582882881165\n",
            "step :  28500 iters_100_time :  77.95881152153015\n",
            "step :  28600 iters_100_time :  78.02023267745972\n",
            "step :  28700 iters_100_time :  77.98110222816467\n",
            "[455/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 66.74 Time: 346.05s\n",
            "num_batches :  442\n",
            "step :  28800 iters_100_time :  55.1288366317749\n",
            "step :  28900 iters_100_time :  77.94685578346252\n",
            "step :  29000 iters_100_time :  78.49551153182983\n",
            "step :  29100 iters_100_time :  78.14078378677368\n",
            "[456/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 79.76 Time: 346.83s\n",
            "num_batches :  442\n",
            "step :  29200 iters_100_time :  22.65304923057556\n",
            "step :  29300 iters_100_time :  78.78050971031189\n",
            "step :  29400 iters_100_time :  78.19120264053345\n",
            "step :  29500 iters_100_time :  78.69981145858765\n",
            "step :  29600 iters_100_time :  77.28803491592407\n",
            "[457/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 59.36 Time: 347.04s\n",
            "num_batches :  442\n",
            "step :  29700 iters_100_time :  68.52286410331726\n",
            "step :  29800 iters_100_time :  78.28558301925659\n",
            "step :  29900 iters_100_time :  78.49495840072632\n",
            "step :  30000 iters_100_time :  78.36122012138367\n",
            "step :  30000 iters_5000_time :  303.6647961139679\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.531114101409912\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.606769800186157\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  225.69448494911194\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "[458/600][442]\n",
            "                    Loss_D: 0.58 Loss_G: 56.59 Time: 632.49s\n",
            "num_batches :  442\n",
            "step :  30100 iters_100_time :  35.542539834976196\n",
            "step :  30200 iters_100_time :  78.88735818862915\n",
            "step :  30300 iters_100_time :  78.43459391593933\n",
            "step :  30400 iters_100_time :  78.92534184455872\n",
            "[459/600][442]\n",
            "                    Loss_D: 0.87 Loss_G: 68.66 Time: 349.01s\n",
            "num_batches :  442\n",
            "step :  30500 iters_100_time :  2.273977518081665\n",
            "step :  30600 iters_100_time :  78.9500823020935\n",
            "step :  30700 iters_100_time :  78.70694518089294\n",
            "step :  30800 iters_100_time :  79.2436671257019\n",
            "step :  30900 iters_100_time :  78.34624314308167\n",
            "[460/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 73.83 Time: 349.70s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  31000 iters_100_time :  48.440945625305176\n",
            "step :  31100 iters_100_time :  78.71516728401184\n",
            "step :  31200 iters_100_time :  79.0904974937439\n",
            "step :  31300 iters_100_time :  78.09291458129883\n",
            "[461/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 74.42 Time: 349.47s\n",
            "num_batches :  442\n",
            "step :  31400 iters_100_time :  14.779855966567993\n",
            "step :  31500 iters_100_time :  78.65076637268066\n",
            "step :  31600 iters_100_time :  78.23134422302246\n",
            "step :  31700 iters_100_time :  79.07765579223633\n",
            "step :  31800 iters_100_time :  78.38724851608276\n",
            "[462/600][442]\n",
            "                    Loss_D: 5.83 Loss_G: 44.09 Time: 348.26s\n",
            "num_batches :  442\n",
            "step :  31900 iters_100_time :  60.984400272369385\n",
            "step :  32000 iters_100_time :  78.35340094566345\n",
            "step :  32100 iters_100_time :  78.02459621429443\n",
            "step :  32200 iters_100_time :  78.17575550079346\n",
            "[463/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 57.92 Time: 347.66s\n",
            "num_batches :  442\n",
            "step :  32300 iters_100_time :  27.13472819328308\n",
            "step :  32400 iters_100_time :  78.27856707572937\n",
            "step :  32500 iters_100_time :  78.97148823738098\n",
            "step :  32600 iters_100_time :  78.11289191246033\n",
            "step :  32700 iters_100_time :  79.17845344543457\n",
            "[464/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 68.84 Time: 348.21s\n",
            "num_batches :  442\n",
            "step :  32800 iters_100_time :  72.67946982383728\n",
            "step :  32900 iters_100_time :  78.31822872161865\n",
            "step :  33000 iters_100_time :  78.03477931022644\n",
            "step :  33100 iters_100_time :  78.24330234527588\n",
            "[465/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 68.74 Time: 347.01s\n",
            "num_batches :  442\n",
            "step :  33200 iters_100_time :  40.11516213417053\n",
            "step :  33300 iters_100_time :  77.86615657806396\n",
            "step :  33400 iters_100_time :  78.08774900436401\n",
            "step :  33500 iters_100_time :  78.36378002166748\n",
            "[466/600][442]\n",
            "                    Loss_D: 0.17 Loss_G: 52.13 Time: 347.02s\n",
            "num_batches :  442\n",
            "step :  33600 iters_100_time :  6.784562826156616\n",
            "step :  33700 iters_100_time :  79.3042140007019\n",
            "step :  33800 iters_100_time :  78.30544948577881\n",
            "step :  33900 iters_100_time :  78.55038547515869\n",
            "step :  34000 iters_100_time :  78.21410131454468\n",
            "[467/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 45.49 Time: 348.43s\n",
            "num_batches :  442\n",
            "step :  34100 iters_100_time :  52.563323736190796\n",
            "step :  34200 iters_100_time :  78.75528383255005\n",
            "step :  34300 iters_100_time :  77.95697474479675\n",
            "step :  34400 iters_100_time :  78.80147504806519\n",
            "[468/600][442]\n",
            "                    Loss_D: 0.47 Loss_G: 48.88 Time: 348.39s\n",
            "num_batches :  442\n",
            "step :  34500 iters_100_time :  19.530696153640747\n",
            "step :  34600 iters_100_time :  78.26530361175537\n",
            "step :  34700 iters_100_time :  79.05607748031616\n",
            "step :  34800 iters_100_time :  78.18021059036255\n",
            "step :  34900 iters_100_time :  78.65518426895142\n",
            "[469/600][442]\n",
            "                    Loss_D: 2.53 Loss_G: 37.07 Time: 348.00s\n",
            "num_batches :  442\n",
            "step :  35000 iters_100_time :  65.16952753067017\n",
            "step :  35000 iters_5000_time :  65.16957545280457\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.59179162979126\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.455041646957397\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  221.2236247062683\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  35100 iters_100_time :  358.35739302635193\n",
            "step :  35200 iters_100_time :  78.7102963924408\n",
            "step :  35300 iters_100_time :  78.73594260215759\n",
            "[470/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 53.26 Time: 628.38s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  35400 iters_100_time :  32.271791219711304\n",
            "step :  35500 iters_100_time :  78.74586701393127\n",
            "step :  35600 iters_100_time :  78.72040033340454\n",
            "step :  35700 iters_100_time :  78.64518761634827\n",
            "step :  35800 iters_100_time :  78.97217178344727\n",
            "[471/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 57.82 Time: 349.56s\n",
            "num_batches :  442\n",
            "step :  35900 iters_100_time :  77.86486577987671\n",
            "step :  36000 iters_100_time :  78.82489275932312\n",
            "step :  36100 iters_100_time :  78.6254346370697\n",
            "step :  36200 iters_100_time :  78.95998120307922\n",
            "[472/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 57.41 Time: 349.05s\n",
            "num_batches :  442\n",
            "step :  36300 iters_100_time :  44.83874845504761\n",
            "step :  36400 iters_100_time :  78.10295510292053\n",
            "step :  36500 iters_100_time :  78.81708455085754\n",
            "step :  36600 iters_100_time :  78.35407662391663\n",
            "[473/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 50.83 Time: 348.71s\n",
            "num_batches :  442\n",
            "step :  36700 iters_100_time :  11.50842022895813\n",
            "step :  36800 iters_100_time :  78.029550075531\n",
            "step :  36900 iters_100_time :  78.91707587242126\n",
            "step :  37000 iters_100_time :  78.42905116081238\n",
            "step :  37100 iters_100_time :  78.9173355102539\n",
            "[474/600][442]\n",
            "                    Loss_D: 0.71 Loss_G: 83.91 Time: 348.86s\n",
            "num_batches :  442\n",
            "step :  37200 iters_100_time :  57.38828086853027\n",
            "step :  37300 iters_100_time :  78.97412085533142\n",
            "step :  37400 iters_100_time :  77.89142036437988\n",
            "step :  37500 iters_100_time :  78.51656293869019\n",
            "[475/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 67.06 Time: 347.85s\n",
            "num_batches :  442\n",
            "step :  37600 iters_100_time :  24.120764017105103\n",
            "step :  37700 iters_100_time :  78.54548835754395\n",
            "step :  37800 iters_100_time :  77.79322957992554\n",
            "step :  37900 iters_100_time :  78.13109850883484\n",
            "step :  38000 iters_100_time :  78.21199941635132\n",
            "[476/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 54.14 Time: 347.01s\n",
            "num_batches :  442\n",
            "step :  38100 iters_100_time :  69.01742005348206\n",
            "step :  38200 iters_100_time :  78.32709288597107\n",
            "step :  38300 iters_100_time :  78.05406451225281\n",
            "step :  38400 iters_100_time :  78.5716004371643\n",
            "[477/600][442]\n",
            "                    Loss_D: 2.87 Loss_G: 35.94 Time: 346.07s\n",
            "num_batches :  442\n",
            "step :  38500 iters_100_time :  36.72484254837036\n",
            "step :  38600 iters_100_time :  77.92660713195801\n",
            "step :  38700 iters_100_time :  78.35506701469421\n",
            "step :  38800 iters_100_time :  77.81304454803467\n",
            "[478/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 52.41 Time: 346.97s\n",
            "num_batches :  442\n",
            "step :  38900 iters_100_time :  3.694575548171997\n",
            "step :  39000 iters_100_time :  78.11709713935852\n",
            "step :  39100 iters_100_time :  78.25481033325195\n",
            "step :  39200 iters_100_time :  78.175954580307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hFHcQmD6nzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}